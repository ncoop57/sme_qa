{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easily export jupyter cells to python module\n",
    "https://github.com/fastai/course-v3/blob/master/nbs/dl2/notebook2script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted prep.ipynb to exp/nb_prep.py\r\n"
     ]
    }
   ],
   "source": [
    "! python /tf/main/src/scripts/notebook2script.py prep.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',300)\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = Path('/tf/data/datasets')\n",
    "java_files = sorted(Path(data_path/'mthds_cmts/java/').glob('**/*.gz'))\n",
    "java_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def jsonl_df(file_list, columns, compression=None):\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f, \n",
    "                                   orient='records', \n",
    "                                   compression=compression,\n",
    "                                   lines=True)[columns] \n",
    "                      for f in file_list], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_df = jsonl_df(java_files, ['code', 'docstring'], 'gzip').rename(columns={\"code\": \"query\", \"docstring\": \"res\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(java_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_df.to_csv(data_path/\"mthds_cmts/mthds_cmts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate two csv files\n",
    "csvs = [data_path/'so_posts/1-50000_10-3-19.csv', data_path/'so_posts/50000-56942_10-3-19.csv']\n",
    "df = pd.concat([pd.read_csv(f)\n",
    "           for f in csvs], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(data_path/'so_posts/56942_10-3-19.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path/\"so_posts/56942_10-3-19_formated.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beautifulsoup version\n",
    "white_list = [\"p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def clean_html(post):\n",
    "    \"\"\"Removes all html tags that can occur inside a SO post.\"\"\"\n",
    "    result = re.sub(r\"<.?span[^>]*>|<.?code[^>]*>|<.?p[^>]*>|<.?hr[^>]*>|<.?h[1-3][^>]*>|<.?a[^>]*>|<.?b[^>]*>|<.?blockquote[^>]*>|<.?del[^>]*>|<.?dd[^>]*>|<.?dl[^>]*>|<.?dt[^>]*>|<.?em[^>]*>|<.?i[^>]*>|<.?img[^>]*>|<.?kbd[^>]*>|<.?li[^>]*>|<.?ol[^>]*>|<.?pre[^>]*>|<.?s[^>]*>|<.?sup[^>]*>|<.?sub[^>]*>|<.?strong[^>]*>|<.?strike[^>]*>|<.?ul[^>]*>|<.?br[^>]*>\", \"\", post)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def post_df(df):\n",
    "    \"\"\"Formats Dataframe from scrapped SO posts into query and res columns.\"\"\"\n",
    "    query = list(map('\\n\\n'.join, zip(df[\"q_body\"], df[\"title\"])))\n",
    "    query = list(map(clean_html, query))\n",
    "    res   = list(map(clean_html, df[\"a_body\"]))\n",
    "    new_df = pd.DataFrame({\"query\": query, \"res\": res})\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "formated_df = post_df(df)\n",
    "len(formated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_df.to_csv(data_path/'so_posts/56942_10-3-19_formated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = \"\"\"<p>I have the following code:<hr>\n",
    "<code>\n",
    "/**\n",
    " * Generic version of the Box class.\n",
    " * @param <T> the type of the value being boxed\n",
    " */\n",
    "public class Box<T> {\n",
    "    // T stands for \"Type\"\n",
    "    private T t;\n",
    "\n",
    "    public void set(T t) { this.t = t; }\n",
    "    public T get() { return t; }\n",
    "}\n",
    "</code>\n",
    "</p>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = \"\"\"<p>I have the following code:<hr>\n",
    "<code>\n",
    "/**\n",
    " * Generic version of the Box class.\n",
    " * @param <T> the type of the value being boxed\n",
    " */\n",
    "public class Box<T> {\n",
    "    // T stands for \"Type\"\n",
    "    private T t;\n",
    "\n",
    "    public void set(T t) { this.t = t; }\n",
    "    public T get() { return t; }\n",
    "}\n",
    "</code>\n",
    "<a>              - hyperlink.\n",
    "<b>              - bold, use as last resort <h1>-<h3>, <em>, and <strong> are \n",
    "                   preferred.\n",
    "<blockquote>     - specifies a section that is quoted from another source.\n",
    "<code>           - defines a piece of computer code.\n",
    "<del>            - delete, used to indicate modifications.\n",
    "<dd>             - describes the item in a <dl> description list.\n",
    "<dl>             - description list.\n",
    "<dt>             - title of an item in a <dl> description list.\n",
    "<em>             - emphasized.\n",
    "<h1>, <h2>, <h3> - headings.\n",
    "<i>              - italic.\n",
    "<img>            - specifies an image tag.\n",
    "<kbd>            - represents user input (usually keyboard input).\n",
    "<li>             - list item in an ordered list <ol> or an unordered list <ul>.\n",
    "<ol>             - ordered list.\n",
    "<p>              - paragraph.\n",
    "<pre>            - pre-element displayed in a fixed width font and and \n",
    "                   unchanged line breaks.\n",
    "<s>              - strikethrough.\n",
    "<sup>            - superscript text appears 1/2 character above the baseline \n",
    "                   used for footnotes and other formatting.\n",
    "<sub>            - subscript appears 1/2 character below the baseline.\n",
    "<strong>         - defines important text.\n",
    "<strike>         - strikethrough is deprecated, use <del> instead.\n",
    "<ul>             - unordered list.\n",
    "<br>             - line break.\n",
    "<hr>             - defines a thematic change in the content, usually via a \n",
    "                   horizontal line.\n",
    "</p>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "result = re.sub(r\"<.?p[^>]*>|<.?hr[^>]*>|<.?h[1-3][^>]*>|<.?a[^>]*>|<.?b[^>]*>|<.?blockquote[^>]*>|<.?code[^>]*>|<.?del[^>]*>|<.?dd[^>]*>|<.?dl[^>]*>|<.?dt[^>]*>|<.?em[^>]*>|<.?i[^>]*>|<.?img[^>]*>|<.?kbd[^>]*>|<.?li[^>]*>|<.?ol[^>]*>|<.?pre[^>]*>|<.?s[^>]*>|<.?sup[^>]*>|<.?sub[^>]*>|<.?strong[^>]*>|<.?strike[^>]*>|<.?ul[^>]*>|<.?br[^>]*>\", \"\", post)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def split_data(df):\n",
    "    \"\"\"Split DataFrame into training, validation, and testing sets.\"\"\"\n",
    "    df_trn, tmp = train_test_split(df, test_size = 0.2)\n",
    "    df_val, df_tst = train_test_split(tmp, test_size = 0.5)\n",
    "    \n",
    "    return df_trn, df_val, df_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path/\"so_posts/56942_10-3-19_formated.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, df_val, df_tst = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df) == (len(df_trn) + len(df_val) + len(df_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "df_trn.to_csv(data_path/'so_posts/trn.csv', index=False)\n",
    "df_val.to_csv(data_path/'so_posts/val.csv', index=False)\n",
    "df_tst.to_csv(data_path/'so_posts/tst.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_splits(dfs, output_path):\n",
    "    \"\"\"Save split of DataFrames into corresponding training, validation, and testing csv files.\"\"\"\n",
    "    dfs[0].to_csv(output_path/'trn.csv', index=False)\n",
    "    dfs[1].to_csv(output_path/'val.csv', index=False)\n",
    "    dfs[2].to_csv(output_path/'tst.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_dfs(df, output_path):\n",
    "    \"\"\"Splits and saves a list of DataFrames to corresponding csv files in the output_path.\"\"\"\n",
    "    # split\n",
    "    df_trn, df_val, df_tst = split_data(df)\n",
    "    # Make sure the sizes match\n",
    "    assert len(df) == (len(df_trn) + len(df_val) + len(df_tst))\n",
    "    \n",
    "    # save splits\n",
    "    save_splits((df_trn, df_val, df_tst), output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dfs(java_df, data_path/\"mthds_cmts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(java_df[\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "tags = {\"mthds_cmts\": \"<$comment$>\", \"so_posts\": \"<$qa$>\", \"code_smell\": \"<$dirty$>\"}\n",
    "def tag_task(df, task_name):\n",
    "    \"\"\"Adds special tag to the end of the query based on the type of task.\"\"\"\n",
    "    new_query = list(map(lambda x: x + tags[task_name], df[\"query\"]))\n",
    "    df[\"query\"] = pd.Series(new_query)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_data(path):\n",
    "    \"\"\"Read in the different data splits from some path.\"\"\"\n",
    "    df_trn = pd.read_csv(path/\"trn.csv\")\n",
    "    df_val = pd.read_csv(path/\"val.csv\")\n",
    "    df_tst = pd.read_csv(path/\"tst.csv\")\n",
    "    \n",
    "    return df_trn, df_val, df_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tag_tasks(path):\n",
    "    \"\"\"Tag all tasks that exist in some path.\"\"\"\n",
    "    dfs = []\n",
    "    for task_path in path.glob(\"*\"):\n",
    "        if task_path.stem == \"merged\": continue\n",
    "        dfs.append(\n",
    "            list(\n",
    "                map(lambda x: tag_task(x, task_path.stem), read_data(task_path))\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs = tag_tasks(data_path)\n",
    "print(dfs[0][0][\"query\"][0], dfs[1][0][\"query\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dfs = next(zip(*dfs))\n",
    "print(len(trn_dfs[0]), len(trn_dfs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def merge_dfs(path, output):\n",
    "    \"\"\"Tag and merge tasks into a single DataFrame.\"\"\"\n",
    "    dfs = tag_tasks(path)\n",
    "    merged_dfs = list(map(lambda x: pd.concat(x, ignore_index=True), zip(*dfs)))\n",
    "    save_splits(merged_dfs, output)\n",
    "    \n",
    "    return merged_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfs = merge_dfs(data_path, data_path/\"merged\")\n",
    "# merged_dfs[0][\"query\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = [(\"trn1\", \"tst1\"), (\"trn2\", \"tst2\"), (\"trn3\", \"tst3\")]\n",
    "\n",
    "list(zip(*tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_dfs[0][\"query\"][50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_dfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
