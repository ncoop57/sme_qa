{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easily export jupyter cells to python module\n",
    "https://github.com/fastai/course-v3/blob/master/nbs/dl2/notebook2script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted proc.ipynb to exp/nb_proc.py\r\n"
     ]
    }
   ],
   "source": [
    "! python /tf/main/src/scripts/notebook2script.py proc.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "from fastai.text import *\n",
    "\n",
    "import pandas as pd\n",
    "import sentencepiece as sp\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from prep.exp.nb_prep import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def df_to_txt_file(df, output):\n",
    "    with open(output/'text.txt', 'w') as f:\n",
    "        f.write('\\n'.join(list(merged_trn_df[\"query\"]) + list(merged_trn_df[\"res\"])))\n",
    "    return output/'text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gen_sp_model(df, output):\n",
    "    fname = df_to_txt_file(df, output)\n",
    "    sp.SentencePieceTrainer.train(f'--input={fname} --model_prefix={output}/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SentencePiece:\n",
    "    \"SentencePiece wrapper.\"\n",
    "    def __init__(self, mdl_path):\n",
    "        self.mdl_path = mdl_path\n",
    "        self.s = sp.SentencePieceProcessor()\n",
    "        self.s.Load(str(mdl_path))\n",
    "        self.vocab = [self.s.IdToPiece(id) for id in range(self.s.GetPieceSize())]\n",
    "        \n",
    "    def tokenize(self, inpt):\n",
    "        return self.s.EncodeAsPieces(inpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = sp.SentencePieceProcessor()\n",
    "s.Load(str(data_path/\"merged/model.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.SampleEncodeAsPieces??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(20):\n",
    "    print(len(s.EncodeAsIds('public static void adfaj')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/tf/data/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trn_df = pd.read_csv(data_path/\"merged/trn.csv\")\n",
    "merged_trn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_txt_file(merged_trn_df, data_path/\"merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sp_model(merged_trn_df, data_path/\"merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trn_df.head(1).to_string(header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"yo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_trn_df?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path/'merged/text.txt', 'w') as f:\n",
    "    f.write('\\n'.join(list(merged_trn_df.head(2)[\"query\"]) + list(merged_trn_df.head(2)[\"res\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(merged_trn_df.head(2)[\"query\"]) + list(merged_trn_df.head(2)[\"res\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def merge_cols(df):\n",
    "    merged = [''.join(x) for x in zip(df[\"query\"], df[\"res\"])]\n",
    "    new_df = pd.DataFrame({\"merged\": merged})\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv_to_ds(df, data_path, bs = 64):\n",
    "#     print(df.head(5))\n",
    "    return (TextList\n",
    "            .from_df(df, data_path, \n",
    "                     processor = SPProcessor(\n",
    "                         sp_model = data_path/\"merged/model.model\",\n",
    "                         sp_vocab = data_path/\"merged/model.vocab\"\n",
    "                     ))\n",
    "            .split_none()\n",
    "            .label_for_lm()\n",
    "            .databunch(bs = bs)\n",
    "           ).train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gen_lm_data(df_trn, df_val, task_name, data_path, bs = 64, sample = 1):\n",
    "    if task_name != \"merged\":\n",
    "        df_trn = tag_task(df_trn, task_name)\n",
    "        df_val = tag_task(df_val, task_name)\n",
    "    \n",
    "    df_trn = df_trn.sample(frac = sample)\n",
    "    df_val = df_val.sample(frac = sample)\n",
    "    \n",
    "    df_trn = merge_cols(df_trn)\n",
    "    df_val = merge_cols(df_val)\n",
    "    \n",
    "    ds_trn = conv_to_ds(df_trn, data_path)\n",
    "    ds_val = conv_to_ds(df_val, data_path)\n",
    "        \n",
    "    data = TextLMDataBunch.create(\n",
    "        train_ds = ds_trn, valid_ds = ds_val, path = data_path, bs = bs\n",
    "    )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, df_val, df_tst = read_data(data_path/\"merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn[\"query\"][10], df_trn[\"res\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gen_lm_data(df_trn, df_val, \"merged\", data_path, sample = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.train_ds), len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bunch of Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = db.dl(DatasetType.Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " db2 = TextLMDataBunch.create(\n",
    "        train_ds = db.train_dl.dl.dataset,\n",
    "        valid_ds = db.train_dl.dl.dataset, path = data_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db2.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = db.databunch(bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = (TextList\n",
    "            .from_df(df_trn[:100], data_path, \n",
    "                     processor = SPProcessor(\n",
    "                         sp_model = data_path/\"merged/model.model\",\n",
    "                         sp_vocab = data_path/\"merged/model.vocab\"\n",
    "                     ))\n",
    "            .split_none()\n",
    "            .label_for_lm()\n",
    "#             .databunch(bs=64)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d1.databunch(bs=64)\n",
    "d2.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_dl.dl.dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = (TextList\n",
    "            .from_df(df_trn[:100], data_path, \n",
    "                     processor = SPProcessor(\n",
    "                         sp_model = data_path/\"merged/model.model\",\n",
    "                         sp_vocab = data_path/\"merged/model.vocab\"\n",
    "                     ))\n",
    "            .split_none()\n",
    "            .label_for_lm()\n",
    "            .databunch(bs=64)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.train_dl.dl.dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
