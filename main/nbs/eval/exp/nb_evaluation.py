
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/evaluation.ipynb

# imports
from fastai.text import *

# Evaluation metrics for vulnerability detection - Accuracy, Precision, Recall
def eval_vuln(mdl, tst, sp):
    tps, tns, fps, fns = 0, 0, 0, 0
    tot = 0
    for inpt, lbl in zip(tst["query"], tst["res"]):
        tok_len = len(sp.EncodeAsPieces(inpt))
        if tok_len > 1024:
            continue
        pred = get_res(mdl, inpt, sp, n_toks = 10)
        if lbl == "yes":
            if pred == lbl:
                tps += 1
            else: fns += 1
        else:
            if pred == lbl:
                tns += 1
            else: fps += 1

        tot += 1
        torch.cuda.empty_cache()

    acc   = (tps + tns) / tot
    prec  = tps / (tps + fps) if (tps + fps) != 0 else 0.
    recal = tps / (tps + fns) if (tps + fns) != 0 else 0.

    return acc, prec, recal

# Dependency downloads
import nltk
# required for meteor to perform similarity score, etc by looking for synonyms, antonyms...
nltk.download('wordnet')

from typing import List
from nltk.translate.bleu_score import sentence_bleu
from nltk.tokenize import RegexpTokenizer

tokenizer = RegexpTokenizer(r'\w+')

def _eval_bleu(reference_texts: List[str], generated_text: str, weights: List[int]):
    tokenized_references = [tokenizer.tokenize(reference) for reference in reference_texts]
    tokenized_generated_text = tokenizer.tokenize(generated_text)
    return round(sentence_bleu(
        tokenized_references,
        tokenized_generated_text,
        weights=weights),
        4)

def eval_bleu1(reference_texts: List[str], generated_text: str):
    return _eval_bleu(reference_texts,
                      generated_text,
                      weights = (1,0,0,0))

def eval_bleu2(reference_texts: List[str], generated_text: str):
    return _eval_bleu(reference_texts,
                      generated_text,
                      weights = (0.5,0.5,0,0))

def eval_bleu3(reference_texts: List[str], generated_text: str):
    return _eval_bleu(reference_texts,
                      generated_text,
                      weights = (0.33,0.33,0.33,0))

def eval_bleu4(reference_texts: List[str], generated_text: str):
    return _eval_bleu(reference_texts,
                      generated_text,
                      weights = (0.25,0.25,0.25,0.25))

from nltk.translate.meteor_score import meteor_score
def eval_meteor(reference_texts: List[str], generated_text: str):
    return round(meteor_score(reference_texts, generated_text, preprocess=str.lower), 4)

nltk.download('punkt')

import rouge
import pandas as pd

def _eval_rougeL_single_ref(reference_text: str, generated_text: str):
    evaluator = rouge.Rouge(metrics=['rouge-l'],
                           max_n=4,
#                            limit_length=True,
#                            length_limit=100,
#                            length_limit_type='words',
                           apply_avg=0,
                           apply_best=0,
                           alpha=0.5, # Default F1_score
                           weight_factor=1.2,
                           stemming=True)
    # scores = evaluator.get_scores(all_hypothesis, all_references)
    # watch out, it takes hypothesis first and then references.
    score = evaluator.get_scores(generated_text, reference_text)['rouge-l'][0]
    score_p = score['p'][0]
    score_f = score['f'][0]
    score_r = score['r'][0]
    return [score_p, score_r, score_f]

def eval_rougeL_single_ref(reference_text: List[str], generated_text: str):
    evaluator = rouge.Rouge(metrics=['rouge-l'],
                           max_n=4,
#                            limit_length=True,
#                            length_limit=100,
#                            length_limit_type='words',
                           apply_avg=0,
                           apply_best=0,
                           alpha=0.5, # Default F1_score
                           weight_factor=1.2,
                           stemming=True)
    # scores = evaluator.get_scores(all_hypothesis, all_references)
    # watch out, it takes hypothesis first and then references.
    score = evaluator.get_scores(generated_text, reference_text[0])['rouge-l'][0]
    score_p = score['p'][0]
    score_f = score['f'][0]
    score_r = score['r'][0]
    return (score_p, score_r, score_f)

def eval_rougeL(reference_texts: List[str], generated_text: str):
    scores = [
        _eval_rougeL_single_ref(
            reference,
            generated_text)
        for reference in reference_texts]
#     return scores
    result_df = pd.DataFrame(scores)
    # be extra careful, mislabeling is going to be really damaging.
    result_df.columns=['p', 'r', 'f']
    return result_df


def eval_txt(mdl, ds, sp):
    b1, b2, b3, b4 = [], [], [], []
    meteor = []
    rouge_l = []
    preds = []
    tokenizer = Tokenizer()
    for inpt, lbl in zip(ds["query"], ds["res"]):
        tok_len = len(sp.EncodeAsPieces(inpt))
        if tok_len > 1024:
            continue

        pred = get_res(mdl, inpt, sp, n_toks = 600)

        tokens = tokenizer.process_all([lbl])
        lbl = ' '.join(tokens[0])
        preds.append((pred, lbl))

        # bleu 1-4
        b1.append(eval_bleu1([lbl], pred))
        b2.append(eval_bleu2([lbl], pred))
        b3.append(eval_bleu3([lbl], pred))
        b4.append(eval_bleu4([lbl], pred))

        # meteor
        meteor.append(eval_meteor([lbl], pred))

        # rouge
#         rouge_l.append(eval_rougeL_single_ref([lbl], pred))

    return b1, b2, b3, b4, meteor, preds

# Grabs entire model's response up until special xxbos token,
# i.e. once model begins a new sentence we consider the model finished with its answer.
def get_res(mdl, inpt, sp, n_toks = 1_000):
    res = mdl.predict(inpt, n_toks, temperature=0.75).split(" ")
    res = sp.DecodePieces(res).split(" ")
    try:
        end_res = res.index("xxbos")
    except:
        end_res = len(res) - 1

    res = " ".join(res[:end_res])[len(inpt.replace(" ", '')):]

    return res