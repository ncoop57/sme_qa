{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sklearn nltk rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from statistics import mean, median, stdev\n",
    "\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from eval.exp.nb_evaluation import *\n",
    "from eval.exp.nb_plot import *\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "from src.prep.exp.nb_prep import *\n",
    "from src.proc.exp.nb_proc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup paths and model type\n",
    "model_path = Path(\"/tf/data/models\")\n",
    "data_path  = Path(\"/tf/data/datasets\")\n",
    "\n",
    "model     = \"transformer\"\n",
    "task_type = \"merged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(data_path/\"merged/model.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, df_val, df_tst = read_data(data_path/task_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_trn), len(df_val), len(df_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of data to be used: sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_trn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bab967dcbdf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_lm_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_type\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data_lm_100pct.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_trn' is not defined"
     ]
    }
   ],
   "source": [
    "data = gen_lm_data(df_trn, df_val, task_type, data_path, bs = bs)\n",
    "data.save(task_type + '/data_lm_100pct.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = load_data(data_path/task_type, 'data_lm_100pct.pkl', bs = bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492904, 105363)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.train_ds), len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>); ▁} ▁finally ▁{ ▁close ( is ); ▁} ▁}&lt;$ comment $&gt; co p ies ▁bytes ▁from ▁the ▁x x up ▁url ▁&lt; code &gt; source &lt; ▁/ ▁code &gt; ▁to ▁a ▁file ▁&lt; code &gt; destination &lt; ▁/ ▁code &gt; . ▁x x ma j ▁the ▁direct or ies ▁up ▁to ▁&lt; code &gt; destination &lt; ▁/ ▁code &gt; ▁will ▁be ▁created ▁if ▁they ▁don ' t ▁already ▁exist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>; ▁}&lt;$ comment $&gt; use ▁this ▁x x up ▁api ▁to ▁fetch ▁ aaa user _ aaa group _ binding ▁resources ▁of ▁given ▁name ▁ . ▁x x bo s ▁public ▁synchronized ▁boolean ▁has new data () ▁{ ▁return ▁has new ; ▁}&lt;$ b ug $&gt; yes ▁x x bo s ▁x x ma j ▁my ▁main activity ▁class ▁has ▁an ▁if ▁that ▁check s ▁is ▁something ▁is ▁true ▁it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>, ▁if match ) . to block ing (). single (). body (); ▁}&lt;$ comment $&gt; ab or ts ▁an ▁ unlock ed ▁ im mut ability ▁policy . ▁x x ma j ▁the ▁response ▁of ▁delete ▁has ▁ im mut ability period since c re ation in day s ▁set ▁to ▁0 . ▁e tag ▁in ▁if - match ▁is ▁required ▁for ▁this ▁operation . ▁x x ma j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁int ▁i ▁= ▁0; ▁i ▁&lt; ▁split s . size -2 ; ▁i ++ ▁ ) ▁{ ▁if ( ▁select split be t we en ( split s . data [ i ], split s . data [ i + 2 ]) ▁&lt; ▁0 ▁ ) ▁{ ▁/ ▁/ ▁merge ▁the ▁two ▁lines ▁by ▁not ▁adding ▁it ▁change ▁= ▁true ; ▁} ▁else ▁{ ▁work . add ( split s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁= ▁0; ▁i ▁&lt; ▁write list . size (); ▁i ++) ▁{ ▁if ( trace component . is any tra c ing enabled () ▁&amp;&amp; ▁tc . is debug enabled ()) ▁ sib tr . debug ( tc , ▁\" set ting ▁\" ▁+ ▁write list . get ( i ) ▁+ ▁\" ▁at ▁index ▁\" ▁+ ▁( i + ▁index ) ▁ ); ▁block vector . set ( i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amit experiments\n",
    "learn = language_model_learner(\n",
    "    data, Transformer, pretrained = pretrained, metrics=[accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 5e-4\n",
    "moms = (0.75, 0.825)\n",
    "pct_strt = 0.02\n",
    "a_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_fns = [\n",
    "    callbacks.SaveModelCallback(\n",
    "        learn, every='improvement',\n",
    "        monitor='valid_loss', name=f'{model}_{task_type}_save_model'\n",
    "    ),\n",
    "    callbacks.EarlyStoppingCallback(\n",
    "        learn, monitor='valid_loss', min_delta = 0.01,\n",
    "        patience = 3\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#amit experiments\n",
    "learn.fit_one_cycle(\n",
    "    a_epochs, max_lr, moms = moms,\n",
    "    pct_start = pct_strt, callbacks = callback_fns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST -H 'Content-type: application/json' --data '{\"text\":\"from: semeru tower 1\\nstatus: model finished training\"}' https://hooks.slack.com/services/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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (492904 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁public ▁static ▁void ▁copy url to file ( final ▁x x up ▁url ▁source , ▁final ▁x x ma j ▁file ▁destination ) ▁throws ▁ unchecked io exception ▁{ ▁input stream ▁is ▁= ▁null ; ▁try ▁{ ▁is ▁= ▁source . open stream (); ▁write ( destination , ▁is ); ▁} ▁catch ▁( io exception ▁e ) ▁{ ▁throw ▁new ▁ unchecked io exception ( e ); ▁} ▁finally ▁{ ▁close ( is ); ▁} ▁}<$ comment $> co p ies ▁bytes ▁from ▁the ▁x x up ▁url ▁< code > source < ▁/ ▁code > ▁to ▁a ▁file ▁< code > destination < ▁/ ▁code > . ▁x x ma j ▁the ▁direct or ies ▁up ▁to ▁< code > destination < ▁/ ▁code > ▁will ▁be ▁created ▁if ▁they ▁don ' t ▁already ▁exist . ▁< code > destination < ▁/ ▁code > ▁will ▁be ▁over written ▁if ▁it ▁already ▁exists . ▁< p > ▁x x ma j ▁warning : ▁this ▁method ▁does ▁not ▁set ▁a ▁connection ▁or ▁read ▁timeout ▁and ▁thus ▁might ▁block ▁for ever . ▁x x ma j ▁use ▁{@ link ▁# ▁copy url to file ( url , ▁x x ma j ▁file , ▁int , ▁int )} ▁with ▁reason able ▁timeout s ▁to ▁prevent ▁this . ▁@ param ▁source ▁the ▁< code > url < ▁/ ▁code > ▁to ▁copy ▁bytes ▁from , ▁must ▁not ▁be ▁{@ code ▁null } ▁@ param ▁destination ▁the ▁non - directory ▁< code > file < ▁/ ▁code > ▁to ▁write ▁bytes ▁to ▁( possibly ▁over writing ) , ▁must ▁not ▁be ▁{@ code ▁null } ▁@ throws ▁ unchecked io exception ▁if ▁< code > source < ▁/ ▁code > ▁x x up ▁url ▁cannot ▁be ▁open ed ▁@ throws ▁ unchecked io exception ▁if ▁< code > destination < ▁/ ▁code > ▁is ▁a ▁directory ▁@ throws ▁ unchecked io exception ▁if ▁< code > destination < ▁/ ▁code > ▁cannot ▁be ▁written ▁@ throws ▁ unchecked io exception ▁if ▁< code > destination < ▁/ ▁code > ▁needs ▁creating ▁but ▁can ' t ▁be ▁@ throws ▁ unchecked io exception ▁if ▁an ▁x x up ▁ io ▁error ▁occurs ▁during ▁copy ing,▁x x bo s ▁public ▁java . util . list < pl . ed u . ag h . analyze r . model . pre s s release > ▁get pre s s release s ( java . lang . string ▁month , ▁java . lang . string ▁year ) ▁{ ▁if ▁( ( pre s s release repository ) ▁== ▁null ) ▁{ ▁java . lang . system . out . println (\" repository ▁not ▁initial is ed \"); ▁return ▁new ▁java . util . array list <>(); ▁} ▁java . util . list < pl . ed u . ag h . analyze r . model . pre s s release > ▁result ▁= ▁pre s s release repository . find by month and year ( month , ▁year ); ▁if ▁( ( result ▁== ▁null ) ▁|| ▁( ( result . size ()) ▁< ▁1) ) ▁{ ▁java . lang . system . out . println (\" co ul d n ' t ▁find ▁current ▁date ▁- ▁all ▁entries ▁will ▁be ▁retrieved \"); ▁result ▁= ▁( ( java . util . list < pl . ed u . ag h . analyze r . model . pre s s release > ) ▁( pre s s release repository . find all ())); ▁} ▁return ▁result ; ▁}<$ b ug $> yes,▁x x bo s ▁i ▁have ▁a ▁linked list ▁and ▁its ▁elements ▁are ▁book s . ▁x x ma j ▁book s ▁have ▁their ▁price s ▁and ▁a ▁book ▁can ▁be ▁added ▁to ▁the ▁list ▁repeat ed ly ( un - order ed ) ▁and ▁each ▁time ▁when ▁they ▁are ▁added ▁their ▁price s ▁may ▁var y . ▁x x ma j ▁now ▁i ▁have ▁to ▁find ▁the ▁best ▁ s ell ing ▁book ▁in ▁the ▁list ▁by ▁adding ▁up ▁all ▁the ▁different ▁price s ▁of ▁the ▁same ▁book ▁and ▁ divide ▁it ▁by ▁the ▁number ▁of ▁occurrence ▁in ▁the ▁list . ▁i ▁am ▁having ▁trouble ▁with ▁the ▁find ing ▁all ▁the ▁occurrence ▁of ▁the ▁same ▁book ▁as ▁they ▁are ▁un - order ed . ▁can ▁anyone ▁give ▁some ▁idea s ▁about ▁this . ▁than k ▁you . ▁how ▁do ▁i ▁find ▁the ▁average ▁in ▁a ▁x x ma j ▁java ▁linked list ? <$ qa $> is ▁there ▁a any ▁specific ▁reason ▁you ▁are ▁using ▁a ▁linked list ? if ▁not ▁a ▁map ▁can ▁make ▁your ▁life ▁a ▁lot ▁easier : ▁map < string , ▁list < book >> ▁book sh el f ▁= ▁new ▁hash map < string , ▁list < book >> (); ▁void ▁add book ( book ▁book ) ▁{ ▁x x ma j ▁string ▁key ▁= ▁book . name ▁+ ▁book . author ; ▁/ ▁/ ▁x x ma j ▁for ▁ ill u str ation ▁list < book > ▁book list ▁= ▁null ; ▁if ▁(! book sh el f . contains key ( key )) ▁{ ▁book list ▁= ▁new ▁array list < book >(); ▁book sh el f . put ( key , ▁book list ); ▁} ▁else ▁{ ▁book list ▁= ▁book sh el f . get ( key ); ▁} ▁book list . add ( book ); ▁} ▁double ▁fetch av er age ( book ▁input ){ ▁x x ma j ▁string ▁key ▁= ▁\"\" ▁/ ▁* key ▁logic * ▁/ ▁ ; ▁list < book > ▁book list ▁= ▁book sh el f . get ( key ); ▁double ▁a v g ▁= ▁0.0 ; ▁for ( book ▁b : ▁book list ){ ▁a v g ▁+= ▁b . price ; ▁} ▁return ▁a v g ▁/ ▁book list . size (); ▁} ▁x x up ▁or ▁in ▁case ▁of ▁linked list : ▁linked list < book > ▁book list ▁= ▁new ▁linked list < book >(); ▁double ▁a v g ▁= ▁0.0 ; ▁int ▁counter ▁= ▁0; ▁for ▁( book ▁b ▁: ▁book list ) ▁{ ▁if ▁( b . equals ( input book )) ▁{ ▁/ ▁/ ▁must ▁override ▁hash code () ▁and ▁ equals ▁in ▁/ ▁/ ▁x x ma j ▁book ▁and ▁it ▁should ▁be ▁in dependent ▁of ▁/ ▁/ ▁price ▁a v g ▁+= ▁b . price ; ▁counter ++; ▁} ▁} ▁return ▁a v g ▁/ ▁counter ; ▁x x ma j ▁you ▁can ▁probably ▁ enhance ▁it ▁by ▁keep ing ▁the ▁x x ma j ▁list ▁sorted , ▁so ▁all ▁book s ▁with ▁same ▁name ▁and ▁ author ▁occur e ▁con se cut ive ly . ▁x x up ▁or ▁x x ma j ▁maintain ▁a ▁temporary list ▁in ▁case ▁you ▁don ' t ▁want ▁to ▁override ▁ equals : ▁linked list < book > ▁temporary book list ▁= ▁new ▁linked list < book >(); ▁for ▁( book ▁b ▁: ▁book list ) ▁{ ▁if ▁( b . name . equals ( input book . name ) ▁x x re p ▁4 ▁& ▁b . author . equals ( input book . author )) ▁{ ▁temporary book list . add ( b ); ▁} ▁} ▁double ▁a v g ▁= ▁0.0 ; ▁for ( book ▁b ▁: ▁temporary book list ){ ▁a v g ▁+= ▁b . price ; ▁} ▁return ▁a v g ▁/ ▁temporary book list . size (); ▁x x ma j ▁note : ▁price s ▁are ▁in ▁double ▁only ▁for ▁ ill u str ation . ▁x x ma j ▁use ▁of ▁big decimal ▁is ▁ enc our ag ed ▁for ▁price s ▁and ▁such .,▁x x bo s ▁public ▁final ▁void ▁delete application ( string ▁name ) ▁{ ▁delete application request ▁request ▁= ▁delete application request . new builder (). set name ( name ) . build (); ▁delete application ( request ); ▁}<$ comment $> delete s ▁specified ▁application . ▁< p > sample ▁code : ▁< pre >< code > ▁try ▁( application service client ▁application service client ▁= ▁application service client . create ()) ▁{ ▁application name ▁name ▁= ▁application name . of (\"[ project ]\", ▁x x up ▁\"[ tenant ]\", ▁x x up ▁\"[ profile ]\", ▁x x up ▁\"[ application ]\"); ▁application service client . delete application ( name . to string ()); ▁} ▁< ▁/ ▁code >< ▁/ ▁pre > ▁@ param ▁name ▁x x ma j ▁required . ▁< p > the ▁resource ▁name ▁of ▁the ▁application ▁to ▁be ▁deleted . ▁< p > the ▁format ▁is ▁\" project s ▁/ ▁{ project _ id } ▁/ ▁ tenant s ▁/ ▁{ tenant _ id } ▁/ ▁profile s ▁/ ▁{ profile _ id } ▁/ ▁application s ▁/ ▁{ application _ id } \", ▁for ▁example , ▁\" project s ▁/ ▁test - project ▁/ ▁ tenant s ▁/ ▁test - tenant ▁/ ▁profile s ▁/ ▁test - profile ▁/ ▁application s ▁/ ▁test - application \" . ▁@ throws ▁com . google . api . gax . rpc . api exception ▁if ▁the ▁remote ▁call ▁fails,▁x x bo s ▁public ▁void ▁run to ol ( final ▁java . lang . string ▁a to ol name , ▁final ▁java . awt . window ▁a parent ) ▁{ ▁if ▁( nl . l x t re me . ol s . client . client controller . log . is log g able ( java . util . logging . level . info )) ▁{ ▁ nl . l x t re me . ol s . client . client controller . log . log ( java . util . logging . level . info , ▁\" running ▁to ol : ▁\" {0} \" ▁... \", ▁a to ol name ); ▁} ▁final ▁ nl . l x t re me . ol s . client . to ol ▁to ol ▁= ▁get to ol ( a to ol name ); ▁if ▁( to ol ▁== ▁null ) ▁{ ▁javax . swing . j option pane . show message dialog ( a parent , ▁ (\" no ▁such ▁to ol ▁found : ▁\" ▁+ ▁a to ol name ) , ▁\" error ▁... \", ▁javax . swing . j option pane . error _ message ); ▁} else ▁{ ▁final ▁ nl . l x t re me . ol s . client . to ol context ▁context ▁= ▁create to ol context (); ▁to ol . process ( a parent , ▁this . data container , ▁context , ▁this ); ▁} ▁update action s (); ▁}<$ b ug $> yes\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /tf/data/datasets;\n",
       "\n",
       "Valid: LabelList (105363 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁public ▁void ▁set it type ( int ▁flag ) ▁{ ▁on ▁= ▁( flag & 0 x 01 ) ! =0; ▁loop ▁= ▁( flag & 0 x 02 ) ! =0; ▁ s us tain ▁= ▁( flag & 0 x 04 ) ! =0; ▁carry ▁= ▁( flag & 0 x 08 ) ! =0; ▁filter ▁= ▁( flag & 0 x 80 ) ! =0; ▁}<$ comment $> set s ▁the ▁boolean ▁values ▁corresponding ▁to ▁the ▁flag ▁value ▁it - version ▁( w hy ▁on ▁ ear th ▁needed ▁this ▁to ▁be ▁swap ed ? ! ) ▁@ since ▁12 . 11 . 200 6 ▁@ param ▁flag,▁x x bo s ▁public ▁org . data v y u . plugin s . plugin ▁get compatible plugin ( final ▁java . lang . string ▁class ifier , ▁final ▁java . io . file ▁file ) ▁{ ▁for ▁( org . data v y u . plugin s . plugin ▁candidate ▁: ▁plugin class ifier s . get ( class ifier )) ▁{ ▁for ▁( org . data v y u . plugin s . filter ▁filter ▁: ▁candidate . get filter s ()) ▁{ ▁if ▁( filter . get file filter (). accept ( file )) ▁{ ▁return ▁candidate ; ▁} ▁} ▁} ▁return ▁null ; ▁}<$ b ug $> yes,▁x x bo s ▁@ java . lang . override ▁@ java . lang . suppress warning s ( value ▁= ▁\" resource \") ▁protected ▁void ▁write ( p and a . log . log event ▁event ) ▁{ ▁java . io . print stream ▁out ; ▁if ▁( ( p and a . log . impl . console log . output ) ▁== ▁null ) ▁{ ▁out ▁= ▁( level . is g re ater or equal ( log level . warn )) ▁? ▁java . lang . system . err ▁: ▁java . lang . system . out ; ▁} else ▁{ ▁out ▁= ▁p and a . log . impl . console log . output ; ▁} ▁java . lang . string ▁msg ▁= ▁format . format ( event ); ▁out . print ( msg ); ▁if ▁( ( event . get error ()) ▁!= ▁null ) ▁{ ▁msg ▁= ▁p and a . lang . exception s . get stack trace ( event . get error ()); ▁out . print ( msg ); ▁} ▁}<$ b ug $> no,▁x x bo s ▁boolean ▁update callback ( task <?> ▁task , ▁x x ma j ▁fragment ▁callback , ▁x x ma j ▁string ▁annotation id ) ▁{ ▁if ▁( callback ▁== ▁null ) ▁{ ▁return ▁false ; ▁} ▁if ▁( update callback ( task , ▁callback . get activity (), ▁annotation id )) ▁{ ▁task . set fragment id ( fragment id help er . get fragment id ( callback )); ▁return ▁true ; ▁} ▁else ▁{ ▁return ▁false ; ▁} ▁}<$ comment $> ▁/ ▁* package,▁x x bo s ▁@ visible for test ing ▁byte buffer ▁ allocate memory () ▁{ ▁if ▁(! boolean . get boolean ( disable _ allocate _ direct _ property )) ▁{ ▁for ▁( int ▁ret rie s ▁= ▁0; ▁ret rie s ▁< ▁x x up ▁memory _ al location _ at temp ts ; ▁ret rie s ++) ▁{ ▁int ▁target capacity ▁= ▁get memory for sort ( ret rie s ); ▁try ▁{ ▁return ▁byte buffer . allocate direct ( target capacity ); ▁} ▁catch ▁( out of memory error ▁e ) ▁{ ▁log . info (\" failed ▁to ▁ allocate ▁direct ▁memory ▁for ▁sort : ▁\" ▁+ ▁target capacity ▁+ ▁\" ▁retry ing ▁with ▁a ▁smaller ▁buffer .\"); ▁} ▁} ▁} ▁x x ma j ▁runtime ▁runtime ▁= ▁runtime . get runtime (); ▁int ▁target capacity ▁= ▁get memory for sort ( memory _ al location _ at temp ts ); ▁try ▁{ ▁if ▁( target capacity ▁< ▁runtime . free memory () ▁+ ▁( runtime . max memory () ▁- ▁runtime . total memory ())) ▁{ ▁log . info (\" using ▁in direct ▁memory ▁allocation .\"); ▁return ▁byte buffer . allocate ( target capacity ); ▁} ▁else ▁{ ▁log . info (\" skip ping ▁in direct ▁memory ▁allocation .\"); ▁} ▁} ▁catch ▁( out of memory error ▁e ) ▁{ ▁log . info (\" failed ▁to ▁ allocate ▁non - direct ▁memory ▁for ▁sort : ▁\" ▁+ ▁target capacity ▁+ ▁\" ▁giving ▁up \"); ▁} ▁throw ▁new ▁ reject request exception (\" failed ▁to ▁ allocate ▁memory ▁for ▁sort ▁after ▁\" ▁+ ▁x x up ▁memory _ al location _ at temp ts ▁+ ▁\" ▁attempt s . ▁x x ma j ▁giving ▁up .\"); ▁}<$ comment $> this ▁attempt s ▁to ▁ allocate ▁as ▁much ▁memory ▁as ▁can ▁be ▁ claim ed ▁for ▁sort ing . ▁x x ma j ▁ ide ally ▁this ▁should ▁be ▁as ▁large ▁as ▁possible . ▁x x ma j ▁however ▁because ▁there ▁may ▁be ▁multiple ▁requests ▁occur ring ▁on ▁the ▁same ▁instance , ▁several ▁attempt s ▁may ▁be ▁made ▁to ▁ allocate ▁a ▁large ▁port ion . ▁@ throws ▁runtime exception ▁x x ma j ▁if ▁we ▁cannot ▁ allocate ▁after ▁several ▁attempt s .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /tf/data/datasets;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): Transformer(\n",
       "    (encoder): Embedding(8000, 768)\n",
       "    (pos_enc): Embedding(512, 768)\n",
       "    (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=8000, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fda2066c1e0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/tf/data/datasets/merged'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (492904 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁public ▁static ▁void ▁copy url to file ( final ▁x x up ▁url ▁source , ▁final ▁x x ma j ▁file ▁destination ) ▁throws ▁ unchecked io exception ▁{ ▁input stream ▁is ▁= ▁null ; ▁try ▁{ ▁is ▁= ▁source . open stream (); ▁write ( destination , ▁is ); ▁} ▁catch ▁( io exception ▁e ) ▁{ ▁throw ▁new ▁ unchecked io exception ( e ); ▁} ▁finally ▁{ ▁close ( is ); ▁} ▁}<$ comment $> co p ies ▁bytes ▁from ▁the ▁x x up ▁url ▁< code > source < ▁/ ▁code > ▁to ▁a ▁file ▁< code > destination < ▁/ ▁code > . ▁x x ma j ▁the ▁direct or ies ▁up ▁to ▁< code > destination < ▁/ ▁code > ▁will ▁be ▁created ▁if ▁they ▁don ' t ▁already ▁exist . ▁< code > destination < ▁/ ▁code > ▁will ▁be ▁over written ▁if ▁it ▁already ▁exists . ▁< p > ▁x x ma j ▁warning : ▁this ▁method ▁does ▁not ▁set ▁a ▁connection ▁or ▁read ▁timeout ▁and ▁thus ▁might ▁block ▁for ever . ▁x x ma j ▁use ▁{@ link ▁# ▁copy url to file ( url , ▁x x ma j ▁file , ▁int , ▁int )} ▁with ▁reason able ▁timeout s ▁to ▁prevent ▁this . ▁@ param ▁source ▁the ▁< code > url < ▁/ ▁code > ▁to ▁copy ▁bytes ▁from , ▁must ▁not ▁be ▁{@ code ▁null } ▁@ param ▁destination ▁the ▁non - directory ▁< code > file < ▁/ ▁code > ▁to ▁write ▁bytes ▁to ▁( possibly ▁over writing ) , ▁must ▁not ▁be ▁{@ code ▁null } ▁@ throws ▁ unchecked io exception ▁if ▁< code > source < ▁/ ▁code > ▁x x up ▁url ▁cannot ▁be ▁open ed ▁@ throws ▁ unchecked io exception ▁if ▁< code > destination < ▁/ ▁code > ▁is ▁a ▁directory ▁@ throws ▁ unchecked io exception ▁if ▁< code > destination < ▁/ ▁code > ▁cannot ▁be ▁written ▁@ throws ▁ unchecked io exception ▁if ▁< code > destination < ▁/ ▁code > ▁needs ▁creating ▁but ▁can ' t ▁be ▁@ throws ▁ unchecked io exception ▁if ▁an ▁x x up ▁ io ▁error ▁occurs ▁during ▁copy ing,▁x x bo s ▁public ▁java . util . list < pl . ed u . ag h . analyze r . model . pre s s release > ▁get pre s s release s ( java . lang . string ▁month , ▁java . lang . string ▁year ) ▁{ ▁if ▁( ( pre s s release repository ) ▁== ▁null ) ▁{ ▁java . lang . system . out . println (\" repository ▁not ▁initial is ed \"); ▁return ▁new ▁java . util . array list <>(); ▁} ▁java . util . list < pl . ed u . ag h . analyze r . model . pre s s release > ▁result ▁= ▁pre s s release repository . find by month and year ( month , ▁year ); ▁if ▁( ( result ▁== ▁null ) ▁|| ▁( ( result . size ()) ▁< ▁1) ) ▁{ ▁java . lang . system . out . println (\" co ul d n ' t ▁find ▁current ▁date ▁- ▁all ▁entries ▁will ▁be ▁retrieved \"); ▁result ▁= ▁( ( java . util . list < pl . ed u . ag h . analyze r . model . pre s s release > ) ▁( pre s s release repository . find all ())); ▁} ▁return ▁result ; ▁}<$ b ug $> yes,▁x x bo s ▁i ▁have ▁a ▁linked list ▁and ▁its ▁elements ▁are ▁book s . ▁x x ma j ▁book s ▁have ▁their ▁price s ▁and ▁a ▁book ▁can ▁be ▁added ▁to ▁the ▁list ▁repeat ed ly ( un - order ed ) ▁and ▁each ▁time ▁when ▁they ▁are ▁added ▁their ▁price s ▁may ▁var y . ▁x x ma j ▁now ▁i ▁have ▁to ▁find ▁the ▁best ▁ s ell ing ▁book ▁in ▁the ▁list ▁by ▁adding ▁up ▁all ▁the ▁different ▁price s ▁of ▁the ▁same ▁book ▁and ▁ divide ▁it ▁by ▁the ▁number ▁of ▁occurrence ▁in ▁the ▁list . ▁i ▁am ▁having ▁trouble ▁with ▁the ▁find ing ▁all ▁the ▁occurrence ▁of ▁the ▁same ▁book ▁as ▁they ▁are ▁un - order ed . ▁can ▁anyone ▁give ▁some ▁idea s ▁about ▁this . ▁than k ▁you . ▁how ▁do ▁i ▁find ▁the ▁average ▁in ▁a ▁x x ma j ▁java ▁linked list ? <$ qa $> is ▁there ▁a any ▁specific ▁reason ▁you ▁are ▁using ▁a ▁linked list ? if ▁not ▁a ▁map ▁can ▁make ▁your ▁life ▁a ▁lot ▁easier : ▁map < string , ▁list < book >> ▁book sh el f ▁= ▁new ▁hash map < string , ▁list < book >> (); ▁void ▁add book ( book ▁book ) ▁{ ▁x x ma j ▁string ▁key ▁= ▁book . name ▁+ ▁book . author ; ▁/ ▁/ ▁x x ma j ▁for ▁ ill u str ation ▁list < book > ▁book list ▁= ▁null ; ▁if ▁(! book sh el f . contains key ( key )) ▁{ ▁book list ▁= ▁new ▁array list < book >(); ▁book sh el f . put ( key , ▁book list ); ▁} ▁else ▁{ ▁book list ▁= ▁book sh el f . get ( key ); ▁} ▁book list . add ( book ); ▁} ▁double ▁fetch av er age ( book ▁input ){ ▁x x ma j ▁string ▁key ▁= ▁\"\" ▁/ ▁* key ▁logic * ▁/ ▁ ; ▁list < book > ▁book list ▁= ▁book sh el f . get ( key ); ▁double ▁a v g ▁= ▁0.0 ; ▁for ( book ▁b : ▁book list ){ ▁a v g ▁+= ▁b . price ; ▁} ▁return ▁a v g ▁/ ▁book list . size (); ▁} ▁x x up ▁or ▁in ▁case ▁of ▁linked list : ▁linked list < book > ▁book list ▁= ▁new ▁linked list < book >(); ▁double ▁a v g ▁= ▁0.0 ; ▁int ▁counter ▁= ▁0; ▁for ▁( book ▁b ▁: ▁book list ) ▁{ ▁if ▁( b . equals ( input book )) ▁{ ▁/ ▁/ ▁must ▁override ▁hash code () ▁and ▁ equals ▁in ▁/ ▁/ ▁x x ma j ▁book ▁and ▁it ▁should ▁be ▁in dependent ▁of ▁/ ▁/ ▁price ▁a v g ▁+= ▁b . price ; ▁counter ++; ▁} ▁} ▁return ▁a v g ▁/ ▁counter ; ▁x x ma j ▁you ▁can ▁probably ▁ enhance ▁it ▁by ▁keep ing ▁the ▁x x ma j ▁list ▁sorted , ▁so ▁all ▁book s ▁with ▁same ▁name ▁and ▁ author ▁occur e ▁con se cut ive ly . ▁x x up ▁or ▁x x ma j ▁maintain ▁a ▁temporary list ▁in ▁case ▁you ▁don ' t ▁want ▁to ▁override ▁ equals : ▁linked list < book > ▁temporary book list ▁= ▁new ▁linked list < book >(); ▁for ▁( book ▁b ▁: ▁book list ) ▁{ ▁if ▁( b . name . equals ( input book . name ) ▁x x re p ▁4 ▁& ▁b . author . equals ( input book . author )) ▁{ ▁temporary book list . add ( b ); ▁} ▁} ▁double ▁a v g ▁= ▁0.0 ; ▁for ( book ▁b ▁: ▁temporary book list ){ ▁a v g ▁+= ▁b . price ; ▁} ▁return ▁a v g ▁/ ▁temporary book list . size (); ▁x x ma j ▁note : ▁price s ▁are ▁in ▁double ▁only ▁for ▁ ill u str ation . ▁x x ma j ▁use ▁of ▁big decimal ▁is ▁ enc our ag ed ▁for ▁price s ▁and ▁such .,▁x x bo s ▁public ▁final ▁void ▁delete application ( string ▁name ) ▁{ ▁delete application request ▁request ▁= ▁delete application request . new builder (). set name ( name ) . build (); ▁delete application ( request ); ▁}<$ comment $> delete s ▁specified ▁application . ▁< p > sample ▁code : ▁< pre >< code > ▁try ▁( application service client ▁application service client ▁= ▁application service client . create ()) ▁{ ▁application name ▁name ▁= ▁application name . of (\"[ project ]\", ▁x x up ▁\"[ tenant ]\", ▁x x up ▁\"[ profile ]\", ▁x x up ▁\"[ application ]\"); ▁application service client . delete application ( name . to string ()); ▁} ▁< ▁/ ▁code >< ▁/ ▁pre > ▁@ param ▁name ▁x x ma j ▁required . ▁< p > the ▁resource ▁name ▁of ▁the ▁application ▁to ▁be ▁deleted . ▁< p > the ▁format ▁is ▁\" project s ▁/ ▁{ project _ id } ▁/ ▁ tenant s ▁/ ▁{ tenant _ id } ▁/ ▁profile s ▁/ ▁{ profile _ id } ▁/ ▁application s ▁/ ▁{ application _ id } \", ▁for ▁example , ▁\" project s ▁/ ▁test - project ▁/ ▁ tenant s ▁/ ▁test - tenant ▁/ ▁profile s ▁/ ▁test - profile ▁/ ▁application s ▁/ ▁test - application \" . ▁@ throws ▁com . google . api . gax . rpc . api exception ▁if ▁the ▁remote ▁call ▁fails,▁x x bo s ▁public ▁void ▁run to ol ( final ▁java . lang . string ▁a to ol name , ▁final ▁java . awt . window ▁a parent ) ▁{ ▁if ▁( nl . l x t re me . ol s . client . client controller . log . is log g able ( java . util . logging . level . info )) ▁{ ▁ nl . l x t re me . ol s . client . client controller . log . log ( java . util . logging . level . info , ▁\" running ▁to ol : ▁\" {0} \" ▁... \", ▁a to ol name ); ▁} ▁final ▁ nl . l x t re me . ol s . client . to ol ▁to ol ▁= ▁get to ol ( a to ol name ); ▁if ▁( to ol ▁== ▁null ) ▁{ ▁javax . swing . j option pane . show message dialog ( a parent , ▁ (\" no ▁such ▁to ol ▁found : ▁\" ▁+ ▁a to ol name ) , ▁\" error ▁... \", ▁javax . swing . j option pane . error _ message ); ▁} else ▁{ ▁final ▁ nl . l x t re me . ol s . client . to ol context ▁context ▁= ▁create to ol context (); ▁to ol . process ( a parent , ▁this . data container , ▁context , ▁this ); ▁} ▁update action s (); ▁}<$ b ug $> yes\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /tf/data/datasets;\n",
       "\n",
       "Valid: LabelList (105363 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁public ▁void ▁set it type ( int ▁flag ) ▁{ ▁on ▁= ▁( flag & 0 x 01 ) ! =0; ▁loop ▁= ▁( flag & 0 x 02 ) ! =0; ▁ s us tain ▁= ▁( flag & 0 x 04 ) ! =0; ▁carry ▁= ▁( flag & 0 x 08 ) ! =0; ▁filter ▁= ▁( flag & 0 x 80 ) ! =0; ▁}<$ comment $> set s ▁the ▁boolean ▁values ▁corresponding ▁to ▁the ▁flag ▁value ▁it - version ▁( w hy ▁on ▁ ear th ▁needed ▁this ▁to ▁be ▁swap ed ? ! ) ▁@ since ▁12 . 11 . 200 6 ▁@ param ▁flag,▁x x bo s ▁public ▁org . data v y u . plugin s . plugin ▁get compatible plugin ( final ▁java . lang . string ▁class ifier , ▁final ▁java . io . file ▁file ) ▁{ ▁for ▁( org . data v y u . plugin s . plugin ▁candidate ▁: ▁plugin class ifier s . get ( class ifier )) ▁{ ▁for ▁( org . data v y u . plugin s . filter ▁filter ▁: ▁candidate . get filter s ()) ▁{ ▁if ▁( filter . get file filter (). accept ( file )) ▁{ ▁return ▁candidate ; ▁} ▁} ▁} ▁return ▁null ; ▁}<$ b ug $> yes,▁x x bo s ▁@ java . lang . override ▁@ java . lang . suppress warning s ( value ▁= ▁\" resource \") ▁protected ▁void ▁write ( p and a . log . log event ▁event ) ▁{ ▁java . io . print stream ▁out ; ▁if ▁( ( p and a . log . impl . console log . output ) ▁== ▁null ) ▁{ ▁out ▁= ▁( level . is g re ater or equal ( log level . warn )) ▁? ▁java . lang . system . err ▁: ▁java . lang . system . out ; ▁} else ▁{ ▁out ▁= ▁p and a . log . impl . console log . output ; ▁} ▁java . lang . string ▁msg ▁= ▁format . format ( event ); ▁out . print ( msg ); ▁if ▁( ( event . get error ()) ▁!= ▁null ) ▁{ ▁msg ▁= ▁p and a . lang . exception s . get stack trace ( event . get error ()); ▁out . print ( msg ); ▁} ▁}<$ b ug $> no,▁x x bo s ▁boolean ▁update callback ( task <?> ▁task , ▁x x ma j ▁fragment ▁callback , ▁x x ma j ▁string ▁annotation id ) ▁{ ▁if ▁( callback ▁== ▁null ) ▁{ ▁return ▁false ; ▁} ▁if ▁( update callback ( task , ▁callback . get activity (), ▁annotation id )) ▁{ ▁task . set fragment id ( fragment id help er . get fragment id ( callback )); ▁return ▁true ; ▁} ▁else ▁{ ▁return ▁false ; ▁} ▁}<$ comment $> ▁/ ▁* package,▁x x bo s ▁@ visible for test ing ▁byte buffer ▁ allocate memory () ▁{ ▁if ▁(! boolean . get boolean ( disable _ allocate _ direct _ property )) ▁{ ▁for ▁( int ▁ret rie s ▁= ▁0; ▁ret rie s ▁< ▁x x up ▁memory _ al location _ at temp ts ; ▁ret rie s ++) ▁{ ▁int ▁target capacity ▁= ▁get memory for sort ( ret rie s ); ▁try ▁{ ▁return ▁byte buffer . allocate direct ( target capacity ); ▁} ▁catch ▁( out of memory error ▁e ) ▁{ ▁log . info (\" failed ▁to ▁ allocate ▁direct ▁memory ▁for ▁sort : ▁\" ▁+ ▁target capacity ▁+ ▁\" ▁retry ing ▁with ▁a ▁smaller ▁buffer .\"); ▁} ▁} ▁} ▁x x ma j ▁runtime ▁runtime ▁= ▁runtime . get runtime (); ▁int ▁target capacity ▁= ▁get memory for sort ( memory _ al location _ at temp ts ); ▁try ▁{ ▁if ▁( target capacity ▁< ▁runtime . free memory () ▁+ ▁( runtime . max memory () ▁- ▁runtime . total memory ())) ▁{ ▁log . info (\" using ▁in direct ▁memory ▁allocation .\"); ▁return ▁byte buffer . allocate ( target capacity ); ▁} ▁else ▁{ ▁log . info (\" skip ping ▁in direct ▁memory ▁allocation .\"); ▁} ▁} ▁catch ▁( out of memory error ▁e ) ▁{ ▁log . info (\" failed ▁to ▁ allocate ▁non - direct ▁memory ▁for ▁sort : ▁\" ▁+ ▁target capacity ▁+ ▁\" ▁giving ▁up \"); ▁} ▁throw ▁new ▁ reject request exception (\" failed ▁to ▁ allocate ▁memory ▁for ▁sort ▁after ▁\" ▁+ ▁x x up ▁memory _ al location _ at temp ts ▁+ ▁\" ▁attempt s . ▁x x ma j ▁giving ▁up .\"); ▁}<$ comment $> this ▁attempt s ▁to ▁ allocate ▁as ▁much ▁memory ▁as ▁can ▁be ▁ claim ed ▁for ▁sort ing . ▁x x ma j ▁ ide ally ▁this ▁should ▁be ▁as ▁large ▁as ▁possible . ▁x x ma j ▁however ▁because ▁there ▁may ▁be ▁multiple ▁requests ▁occur ring ▁on ▁the ▁same ▁instance , ▁several ▁attempt s ▁may ▁be ▁made ▁to ▁ allocate ▁a ▁large ▁port ion . ▁@ throws ▁runtime exception ▁x x ma j ▁if ▁we ▁cannot ▁ allocate ▁after ▁several ▁attempt s .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /tf/data/datasets;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): Transformer(\n",
       "    (encoder): Embedding(8000, 768)\n",
       "    (pos_enc): Embedding(512, 768)\n",
       "    (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadAttention(\n",
       "          (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (drop_att): Dropout(p=0.1, inplace=False)\n",
       "          (drop_res): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GeLU()\n",
       "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): MergeLayer()\n",
       "            (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=8000, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fda2066c1e0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/tf/data/datasets/merged'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): Embedding(8000, 768)\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=8000, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): DecoderLayer(\n",
       "    (mhra): MultiHeadAttention(\n",
       "      (attention): Linear(in_features=768, out_features=2304, bias=True)\n",
       "      (out): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (drop_att): Dropout(p=0.1, inplace=False)\n",
       "      (drop_res): Dropout(p=0.1, inplace=False)\n",
       "      (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (ff): SequentialEx(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): GeLU()\n",
       "        (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "        (4): MergeLayer()\n",
       "        (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): Embedding(8000, 768)\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=768, out_features=8000, bias=False)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(f'{model}_{task_type}_save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.recorder.plot_losses()\n",
    "figure_plot = learn.recorder.plot_losses(return_fig=True)\n",
    "figure_plot.savefig(fname=f\"{model}_{task_type}_plot_losses.png\", format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=432x288 at 0x7FD9E782BBA8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "Image.open(f'/tf/main/nbs/mdling/{model}/{model}_{task_type}_plot_losses.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_len(max_query, max_res, df):\n",
    "    return len(sp.EncodeAsPieces(df[0])) <= max_query and \\\n",
    "           len(sp.EncodeAsPieces(df[1])) <= max_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vulnerability Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_query = 1024\n",
    "max_res   = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = \"buggy\"\n",
    "vuln_trn, vuln_val, vuln_tst = read_data(data_path/task_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuln_val = tag_task(vuln_val, task_type)\n",
    "vuln_val = list(filter(partial(max_len, max_query, max_res),\n",
    "                       zip(vuln_val[\"query\"], vuln_val[\"res\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vuln_val = pd.DataFrame({\"query\": [row[0] for row in vuln_val],\n",
    "                         \"res\": [row[1] for row in vuln_val]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@java.lang.Override\\npublic int onStartCommand...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@java.lang.Override\\nprotected java.lang.Strin...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>private java.lang.StringBuffer declineFriend(i...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>public void setPointIndex(int pointIndex) {\\n ...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>public void changeBufferData(org.rajawali3d.Bu...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  res\n",
       "0  @java.lang.Override\\npublic int onStartCommand...  yes\n",
       "1  @java.lang.Override\\nprotected java.lang.Strin...  yes\n",
       "2  private java.lang.StringBuffer declineFriend(i...  yes\n",
       "3  public void setPointIndex(int pointIndex) {\\n ...  yes\n",
       "4  public void changeBufferData(org.rajawali3d.Bu...  yes"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vuln_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45749"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vuln_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Transformer' object has no attribute 'select_hidden'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-74426032fddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_vuln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvuln_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tf/main/nbs/eval/exp/nb_evaluation.py\u001b[0m in \u001b[0;36meval_vuln\u001b[0;34m(mdl, tst, sp, task, max_toks)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"res\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_toks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreedy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlbl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"yes\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/main/nbs/eval/exp/nb_evaluation.py\u001b[0m in \u001b[0;36mget_res\u001b[0;34m(mdl, inpt, sp, task, n_toks, greedy)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreedy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgreedy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_toks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_sz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecodePieces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, text, n_words, no_unk, top_k, beam_sz, temperature, sep, decoder)\u001b[0m\n\u001b[1;32m    157\u001b[0m                                 indices[:,:,None].expand(nodes.size(0),top_k,1),], dim=2)\n\u001b[1;32m    158\u001b[0m                 \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msort_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msort_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m                 \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtemperature\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    589\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 591\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Transformer' object has no attribute 'select_hidden'"
     ]
    }
   ],
   "source": [
    "acc, prec, recal = eval_vuln(learn, vuln_val[:500], sp, tags[task_type], max_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, prec, recal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST -H 'Content-type: application/json' --data '{\"text\":\"from: semeru tower 2\\nstatus: finished buggy eval\"}' https://hooks.slack.com/services/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"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_query = 512\n",
    "max_res   = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = \"mthds_cmts\"\n",
    "cmt_trn, cmt_val, cmt_tst = read_data(data_path/task_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmt_val = tag_task(cmt_val, task_type)\n",
    "cmt_val = list(filter(partial(max_len, max_query, max_res), zip(cmt_val[\"query\"], cmt_val[\"res\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmt_val = pd.DataFrame({\"query\": [row[0] for row in cmt_val],\n",
    "                        \"res\": [row[1] for row in cmt_val]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>public void addContent(String destSpaceId,\\n  ...</td>\n",
       "      <td>This method pushes the content file to the spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>public ResultList&lt;ChangeKeyItem&gt; getEpisodeCha...</td>\n",
       "      <td>Look up a TV episode's changes by episode ID\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>public ServiceFuture&lt;OperationStatus&gt; deleteCu...</td>\n",
       "      <td>Delete an entity role.\\n\\n@param appId The app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>protected Map&lt;String,Object&gt; createMessageHead...</td>\n",
       "      <td>Reads basic message information such as sender...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>public void marshall(PatchStatus patchStatus, ...</td>\n",
       "      <td>Marshall the given parameter object.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  public void addContent(String destSpaceId,\\n  ...   \n",
       "1  public ResultList<ChangeKeyItem> getEpisodeCha...   \n",
       "2  public ServiceFuture<OperationStatus> deleteCu...   \n",
       "3  protected Map<String,Object> createMessageHead...   \n",
       "4  public void marshall(PatchStatus patchStatus, ...   \n",
       "\n",
       "                                                 res  \n",
       "0  This method pushes the content file to the spa...  \n",
       "1  Look up a TV episode's changes by episode ID\\n...  \n",
       "2  Delete an entity role.\\n\\n@param appId The app...  \n",
       "3  Reads basic message information such as sender...  \n",
       "4               Marshall the given parameter object.  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmt_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43743"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cmt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b1, b2, b3, b4, meteor, rouge_l, levenshtein, cosine, jaccard, preds = eval_txt(\n",
    "    learn, cmt_val[:10], sp, tags[task_type], max_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07135, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(b1), mean(b2), mean(b3), mean(b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_l = np.array(rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05941, array([0.119527, 0.15993 , 0.124988]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(meteor), np.mean(rouge_l, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = box_whisker_plot(levenshtein, \"Levenshtein Distance\", \"Distance\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18367, 0.08089)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(cosine), mean(jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST -H 'Content-type: application/json' --data '{\"text\":\"from: semeru tower 2\\nstatus: finished comment eval\"}' https://hooks.slack.com/services/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"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackOverflow QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_query = 1024\n",
    "max_res   = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = \"so_posts\"\n",
    "so_trn, so_val, so_tst = read_data(data_path/task_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_val = tag_task(so_val, task_type)\n",
    "so_val = list(filter(partial(max_len, max_query, max_res), zip(so_val[\"query\"], so_val[\"res\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_val = pd.DataFrame({\"query\": [row[0] for row in so_val],\n",
    "                        \"res\": [row[1] for row in so_val]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I converted text to Base64 byteArray without a...</td>\n",
       "      <td>return strToBeConverted.replaceFirst(\"^\\uFEFF\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I have map of a map of strings. This map is a ...</td>\n",
       "      <td>Before I say anything, be polite when asking q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I´m read various tutoriais but most of then sh...</td>\n",
       "      <td>I'm assuming you are using the latest 3.0.0-be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I have a Map. Let's say  \\n\\nMap&amp;lt;Long, List...</td>\n",
       "      <td>You had a few syntax errors.\\n\\nThis should pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>In my Eclipse (Kepler 4.3) I have Checkstyle i...</td>\n",
       "      <td>You need to disable Eclipse checking the names...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  I converted text to Base64 byteArray without a...   \n",
       "1  I have map of a map of strings. This map is a ...   \n",
       "2  I´m read various tutoriais but most of then sh...   \n",
       "3  I have a Map. Let's say  \\n\\nMap&lt;Long, List...   \n",
       "4  In my Eclipse (Kepler 4.3) I have Checkstyle i...   \n",
       "\n",
       "                                                 res  \n",
       "0  return strToBeConverted.replaceFirst(\"^\\uFEFF\"...  \n",
       "1  Before I say anything, be polite when asking q...  \n",
       "2  I'm assuming you are using the latest 3.0.0-be...  \n",
       "3  You had a few syntax errors.\\n\\nThis should pr...  \n",
       "4  You need to disable Eclipse checking the names...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4793"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(so_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-a2177068bb32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m b1, b2, b3, b4, meteor, rouge_l, levenshtein, cosine, jaccard, preds = eval_txt(\n\u001b[0;32m----> 2\u001b[0;31m     learn, so_val[:10], sp, tags[task_type], max_res)\n\u001b[0m",
      "\u001b[0;32m/tf/main/nbs/eval/exp/nb_evaluation.py\u001b[0m in \u001b[0;36meval_txt\u001b[0;34m(mdl, ds, sp, task, max_toks)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"res\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_toks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/main/nbs/eval/exp/nb_evaluation.py\u001b[0m in \u001b[0;36mget_res\u001b[0;34m(mdl, inpt, sp, task, n_toks, greedy)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecodePieces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_toks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecodePieces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text, n_words, no_unk, temperature, min_p, sep, decoder)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mnew_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#progress_bar(range(n_words), leave=False):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0;31m#if len(new_idx) == 0: self.model[0].select_hidden([0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mno_unk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUNK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mpred_batch\u001b[0;34m(self, ds_type, batch, reconstruct, with_dropout)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwith_dropout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_dropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_loss_func2activ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36mto_detach\u001b[0;34m(b, cpu)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mItemsList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/core.py\u001b[0m in \u001b[0;36mrecurse\u001b[0;34m(func, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfirst_el\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(x, cpu)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "b1, b2, b3, b4, meteor, rouge_l, levenshtein, cosine, jaccard, preds = eval_txt(\n",
    "    learn, so_val[:10], sp, tags[task_type], max_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean(b1), mean(b2), mean(b3), mean(b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_l = np.array(rouge_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(meteor), np.mean(rouge_l, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = box_whisker_plot(levenshtein, \"Levenshtein Distance\", \"Distance\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(cosine), mean(jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST -H 'Content-type: application/json' --data '{\"text\":\"from: semeru tower 2\\nstatus: finished so_qa eval\"}' https://hooks.slack.com/services/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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
