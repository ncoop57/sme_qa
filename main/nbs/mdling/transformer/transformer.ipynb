{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from eval.exp.nb_evaluation import *\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "from src.proc.exp.nb_proc import *\n",
    "from src.prep.exp.nb_prep import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup paths and model type\n",
    "model_path = Path(\"/tf/data/models\")\n",
    "data_path  = Path(\"/tf/data/datasets\")\n",
    "\n",
    "task_type = \"merged\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, df_val, df_tst = read_data(data_path/task_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of data to be used: sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = gen_lm_data(df_trn, df_val, task_type, data_path, bs = bs)\n",
    "data.save(task_type + '/data_lm_100pct.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = load_data(data_path/task_type, 'data_lm_01pct.pkl', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4929, 1054)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.train_ds), len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amit experiments\n",
    "learn = language_model_learner(data, Transformer, drop_mult = 0.1, pretrained = pretrained, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "max_lr = 1e-2\n",
    "moms = (0.5, .75)\n",
    "pct_strt = 0.02\n",
    "a_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_fns = [\n",
    "    callbacks.SaveModelCallback(\n",
    "        learn, every='improvement',\n",
    "        monitor='valid_loss', name='transformer_save_model'\n",
    "    ),\n",
    "    callbacks.EarlyStoppingCallback(\n",
    "        learn, monitor='valid_loss', min_delta = 0.01,\n",
    "        patience = 3\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amit experiments\n",
    "learn.fit_one_cycle(a_epochs, max_lr, callbacks = callback_fns) #, moms=moms, pct_start = pct_strt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(model_path/'awd_lstm_do_30pct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (4929 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁@ override ▁public ▁void ▁un register service ( service instance < t > ▁service ) ▁throws ▁x x ma j ▁exception ▁{ ▁entry < t > ▁entry ▁= ▁service s . remove ( service . get id ()); ▁internal un register service ( entry ); ▁}<$ comment $> un register ▁/ ▁remove ▁a ▁group ▁instance ▁@ param ▁service ▁the ▁group ▁@ throws ▁x x ma j ▁exception ▁errors,▁x x bo s ▁list < i _ cms simple context menu entry < set < string >>> ▁get menu entries () ▁{ ▁if ▁( m _ menu entries ▁== ▁null ) ▁{ ▁m _ menu entries ▁= ▁new ▁array list < i _ cms simple context menu entry < set < string >>> (); ▁m _ menu entries . add ( new ▁user entry ()); ▁m _ menu entries . add ( new ▁send broadcast entry ()); ▁m _ menu entries . add ( new ▁ kill entry ()); ▁} ▁return ▁m _ menu entries ; ▁}<$ comment $> return s ▁the ▁available ▁menu ▁entries . < p > ▁@ return ▁the ▁menu ▁entries,▁x x bo s ▁public ▁re vo ke ip rule s request ▁with user rule s ( string . . . ▁user rule s ) ▁{ ▁if ▁( this . user rule s ▁== ▁null ) ▁{ ▁set user rule s ( new ▁com . amazonaws . internal . sdk internal list < string > ( user rule s . length )); ▁} ▁for ▁( string ▁ele ▁: ▁user rule s ) ▁{ ▁this . user rule s . add ( ele ); ▁} ▁return ▁this ; ▁}<$ comment $> < p > ▁x x ma j ▁the ▁rules ▁to ▁remove ▁from ▁the ▁group . ▁< ▁/ ▁p > ▁< p > ▁< b > note : < ▁/ ▁b > ▁x x ma j ▁this ▁method ▁appends ▁the ▁values ▁to ▁the ▁existing ▁list ▁( if ▁any ) . ▁x x ma j ▁use ▁{@ link ▁# ▁set user rule s ( java . util . collection )} ▁or ▁{@ link ▁# ▁with user rule s ( java . util . collection )} ▁if ▁you ▁want ▁to ▁override ▁the ▁existing ▁values . ▁< ▁/ ▁p > ▁@ param ▁user rule s ▁x x ma j ▁the ▁rules ▁to ▁remove ▁from ▁the ▁group . ▁@ return ▁x x ma j ▁returns ▁a ▁reference ▁to ▁this ▁object ▁so ▁that ▁method ▁calls ▁can ▁be ▁chained ▁together .,▁x x bo s ▁private ▁double ▁way length ( list < os m node > ▁nodes ) ▁{ ▁double ▁length ▁= ▁0 d ; ▁os m node ▁n 1, ▁n 2; ▁n 1 ▁= ▁nodes . get (0); ▁for ▁( int ▁i ▁= ▁1; ▁i ▁< ▁nodes . size (); ▁i ++) ▁{ ▁n 2 ▁= ▁nodes . get ( i ); ▁length ▁+= ▁lat long util . distance ( ▁double . parse double ( n 1. lat ) , ▁double . parse double ( n 1. lon ) , ▁double . parse double ( n 2. lat ) , ▁double . parse double ( n 2. lon )); ▁n 1 ▁= ▁n 2; ▁} ▁return ▁length ; ▁}<$ comment $> private ▁methods ▁x x re p ▁ 57 ▁-,▁x x bo s ▁private ▁void ▁set task output dir () ▁{ ▁if ▁( this . job state . contains ( configuration key s . writer _ output _ dir )) ▁{ ▁log . warn ( string . format (\" property ▁% s ▁is ▁ deprecated . ▁x x ma j ▁no ▁need ▁to ▁use ▁it ▁if ▁% s ▁is ▁specified . \", ▁configuration key s . writer _ output _ dir , ▁configuration key s . task _ data _ root _ dir _ key )); ▁} ▁else ▁{ ▁x x ma j ▁string ▁working dir ▁= ▁this . job state . get prop ( configuration key s . task _ data _ root _ dir _ key ); ▁this . job state . set prop ( configuration key s . writer _ output _ dir , ▁new ▁path ( work ing dir , ▁task _ output _ dir _ name ) . to string ()); ▁log . info ( string ▁ . format (\" writer ▁x x ma j ▁output ▁x x ma j ▁directory ▁is ▁set ▁to ▁% s . \", ▁this . job state . get prop ( configuration key s . writer _ output _ dir ))); ▁} ▁}<$ comment $> if ▁{@ link ▁configuration key s ▁# ▁x x up ▁writer _ output _ dir } ▁( which ▁is ▁ deprecated ) ▁is ▁specified , ▁use ▁its ▁value . ▁x x ma j ▁otherwise , ▁if ▁{@ link ▁configuration key s ▁# ▁x x up ▁task _ data _ root _ dir _ key } ▁is ▁specified , ▁use ▁its ▁value ▁ plus ▁{@ link ▁# ▁x x up ▁task _ output _ dir _ name }.\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /tf/data/datasets;\n",
       "\n",
       "Valid: LabelList (1054 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁private ▁double ▁cal c total co st () ▁{ ▁double ▁cost ▁= ▁0; ▁for ▁( java . awt . component ▁com ▁: ▁j p store c art . get component s ()) ▁{ ▁if ▁( com ▁instanceof ▁i mat project . component s . sh op ping c art list entry ) ▁{ ▁i mat project . component s . sh op ping c art list entry ▁entry ▁= ▁( ( i mat project . component s . sh op ping c art list entry ) ▁( com )); ▁cost ▁= ▁cost ▁+ ▁( entry . get total ()); ▁} ▁} ▁return ▁cost ; ▁}<$ b ug $> no,▁x x bo s ▁float ▁get float ( int ▁b p ) ▁{ ▁data input stream ▁buf in ▁= ▁new ▁data input stream ( new ▁byte array input stream ( buf , ▁b p , ▁4 )); ▁try ▁{ ▁return ▁buf in . read float (); ▁} ▁catch ▁( io exception ▁e ) ▁{ ▁throw ▁new ▁assertion error ( e ); ▁} ▁}<$ comment $> extract ▁a ▁float ▁at ▁position ▁b p ▁from ▁buf .,▁x x bo s ▁@ java . lang . suppress warning s ( value ▁= ▁\" check style : illegal catch \") ▁public ▁void ▁update sub net route on tunnel up event ( org . open day light . y ang . gen . v 1. ur n . ie tf . param s . xml . ns . y ang . ie tf . y ang . types . rev 13 07 15 . uuid ▁sub net id , ▁java . math . big integer ▁ dp n id ) ▁{ ▁org . open day light . net v i rt . vpn manager . vpn sub net route handler . log . info (\" update sub net route on tunnel up event : ▁x x ma j ▁sub net ▁{} ▁x x ma j ▁ dp n ▁{}\", ▁sub net id . get value (), ▁ dp n id . to string ()); ▁try ▁{ ▁org . open day light . net v i rt . vpn manager . vpn util . lock sub net ( lock manager , ▁sub net id . get value ()); ▁try ▁{ ▁org . open day light . y ang tools . y ang . binding . instance identifier < org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry > ▁sub op identifier ▁= ▁org . open day light . y ang tools . y ang . binding . instance identifier . builder ( org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net op data . class ) . child ( org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry . class , ▁new ▁org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry key ( sub net id )) . build (); ▁com . google . common . base . optional < org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry > ▁optional sub s ▁= ▁org . open day light . net v i rt . vpn manager . vpn util . read ( data broker , ▁ logical data store type . operation al , ▁sub op identifier ); ▁if ▁(! ( optional sub s . is present ())) ▁{ ▁org . open day light . net v i rt . vpn manager . vpn sub net route handler . log . error (\" update sub net route on tunnel up event : ▁sub net op data entry ▁for ▁sub net ▁{} ▁is ▁not ▁available \", ▁sub net id . get value ()); ▁return ▁ ; ▁} ▁org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry ▁sub op entry ▁= ▁optional sub s . get (); ▁org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry builder ▁sub op builder ▁= ▁new ▁org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry builder ( sub op entry ); ▁boolean ▁is external sub net vpn ▁= ▁org . open day light . net v i rt . vpn manager . vpn util . is external sub net vpn ( sub op entry . get vpn name (), ▁sub net id . get value ()); ▁if ▁( ( sub op builder . get route ad v state ()) ▁!= ▁( org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . task state . ad vert is ed )) ▁{ ▁if ▁( ( sub op builder . get n h dp n id ()) ▁== ▁null ) ▁{ ▁e lect new dp n for sub net route ( sub op builder , ▁null , ▁sub net id , ▁null , ▁(! is external sub net vpn )); ▁} else ▁if ▁(! is external sub net vpn ) ▁{ ▁get next h opt ep and publish route ( sub op builder , ▁sub net id ); ▁} ▁} ▁sub op entry ▁= ▁sub op builder . build (); ▁org . open day light . gen i us . md s al util . md s al util . sync write ( data broker , ▁ logical data store type . operation al , ▁sub op identifier , ▁sub op entry ); ▁org . open day light . net v i rt . vpn manager . vpn sub net route handler . log . info ( (\" update sub net route on tunnel up event : ▁x x ma j ▁updated ▁sub net op data entry ▁to ▁x x up ▁op ▁x x ma j ▁data store ▁ tunnel ▁up ▁on ▁ dp n \" ▁+ ▁\" ▁{} ▁for ▁sub net ▁{} \"), ▁ dp n id . to string (), ▁sub net id . get value ()); ▁} ▁catch ▁( java . lang . exception ▁ex ) ▁{ ▁org . open day light . net v i rt . vpn manager . vpn sub net route handler . log . error (\" c re ation ▁of ▁sub net op data entry ▁for ▁sub net ▁{} ▁failed \", ▁sub net id . get value (), ▁ex ); ▁} ▁finally ▁{ ▁org . open day light . net v i rt . vpn manager . vpn util . unlock sub net ( lock manager , ▁sub net id . get value ()); ▁} ▁} ▁catch ▁( java . lang . exception ▁e ) ▁{ ▁org . open day light . net v i rt . vpn manager . vpn sub net route handler . log . error (\" un able ▁to ▁handle ▁ tunnel ▁up ▁event ▁for ▁sub net id ▁{} ▁ dp n id ▁{}\", ▁sub net id . get value (), ▁ dp n id . to string (), ▁e ); ▁} ▁}<$ b ug $> yes,▁x x bo s ▁private ▁void ▁ s peak answer ( java . lang . string ▁msg ) ▁{ ▁title . set visibility ( view . g one ); ▁back . set visibility ( view . g one ); ▁next . set visibility ( view . g one ); ▁ s view . set visibility ( view . g one ); ▁t view . set visibility ( view . g one ); ▁ s view . set click able ( false ); ▁t view . set click able ( false ); ▁r layout . set visibility ( view . visible ); ▁safe p rm image view . set visibility ( view . visible ); ▁safe e y e contact image view . set visibility ( view . g one ); ▁safe bl ob . set visibility ( view . visible ); ▁safe bl ob . set background resource ( r . drawable . safe _ bl ob ); ▁safe record image button . set visibility ( view . visible ); ▁answer text view . set text ( msg ); ▁answer text view . set visibility ( view . g one ); ▁answer image view . set visibility ( view . g one ); ▁back . set background resource ( r . drawable . home _ selector ); ▁back . set visibility ( view . visible ); ▁on record ▁= ▁true ; ▁}<$ b ug $> yes,▁x x bo s ▁@ override ▁protected ▁void ▁on create ( bundle ▁saved instance state ) ▁{ ▁super . on create ( save d instance state ); ▁/ ▁/ ▁x x ma j ▁initialize ▁so cial ize ▁so cial ize . init a sync ( this , ▁new ▁so cial ize init listener () ▁{ ▁@ override ▁public ▁void ▁on error ( so cial ize exception ▁error ) ▁{ ▁/ ▁/ ▁x x ma j ▁handle ▁error ▁} ▁@ override ▁public ▁void ▁on init ( context ▁context , ▁i oc container ▁container ) ▁{ ▁/ ▁/ ▁x x ma j ▁if ▁you ▁want ▁to ▁access ▁x x ma j ▁so cial ize ▁directly , ▁do ▁it ▁here ▁} ▁} ); ▁}<$ comment $> begin - s n ip p et - 0\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /tf/data/datasets;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(8000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6a8a46b1e0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/tf/data/datasets/merged'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (4929 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁@ override ▁public ▁void ▁un register service ( service instance < t > ▁service ) ▁throws ▁x x ma j ▁exception ▁{ ▁entry < t > ▁entry ▁= ▁service s . remove ( service . get id ()); ▁internal un register service ( entry ); ▁}<$ comment $> un register ▁/ ▁remove ▁a ▁group ▁instance ▁@ param ▁service ▁the ▁group ▁@ throws ▁x x ma j ▁exception ▁errors,▁x x bo s ▁list < i _ cms simple context menu entry < set < string >>> ▁get menu entries () ▁{ ▁if ▁( m _ menu entries ▁== ▁null ) ▁{ ▁m _ menu entries ▁= ▁new ▁array list < i _ cms simple context menu entry < set < string >>> (); ▁m _ menu entries . add ( new ▁user entry ()); ▁m _ menu entries . add ( new ▁send broadcast entry ()); ▁m _ menu entries . add ( new ▁ kill entry ()); ▁} ▁return ▁m _ menu entries ; ▁}<$ comment $> return s ▁the ▁available ▁menu ▁entries . < p > ▁@ return ▁the ▁menu ▁entries,▁x x bo s ▁public ▁re vo ke ip rule s request ▁with user rule s ( string . . . ▁user rule s ) ▁{ ▁if ▁( this . user rule s ▁== ▁null ) ▁{ ▁set user rule s ( new ▁com . amazonaws . internal . sdk internal list < string > ( user rule s . length )); ▁} ▁for ▁( string ▁ele ▁: ▁user rule s ) ▁{ ▁this . user rule s . add ( ele ); ▁} ▁return ▁this ; ▁}<$ comment $> < p > ▁x x ma j ▁the ▁rules ▁to ▁remove ▁from ▁the ▁group . ▁< ▁/ ▁p > ▁< p > ▁< b > note : < ▁/ ▁b > ▁x x ma j ▁this ▁method ▁appends ▁the ▁values ▁to ▁the ▁existing ▁list ▁( if ▁any ) . ▁x x ma j ▁use ▁{@ link ▁# ▁set user rule s ( java . util . collection )} ▁or ▁{@ link ▁# ▁with user rule s ( java . util . collection )} ▁if ▁you ▁want ▁to ▁override ▁the ▁existing ▁values . ▁< ▁/ ▁p > ▁@ param ▁user rule s ▁x x ma j ▁the ▁rules ▁to ▁remove ▁from ▁the ▁group . ▁@ return ▁x x ma j ▁returns ▁a ▁reference ▁to ▁this ▁object ▁so ▁that ▁method ▁calls ▁can ▁be ▁chained ▁together .,▁x x bo s ▁private ▁double ▁way length ( list < os m node > ▁nodes ) ▁{ ▁double ▁length ▁= ▁0 d ; ▁os m node ▁n 1, ▁n 2; ▁n 1 ▁= ▁nodes . get (0); ▁for ▁( int ▁i ▁= ▁1; ▁i ▁< ▁nodes . size (); ▁i ++) ▁{ ▁n 2 ▁= ▁nodes . get ( i ); ▁length ▁+= ▁lat long util . distance ( ▁double . parse double ( n 1. lat ) , ▁double . parse double ( n 1. lon ) , ▁double . parse double ( n 2. lat ) , ▁double . parse double ( n 2. lon )); ▁n 1 ▁= ▁n 2; ▁} ▁return ▁length ; ▁}<$ comment $> private ▁methods ▁x x re p ▁ 57 ▁-,▁x x bo s ▁private ▁void ▁set task output dir () ▁{ ▁if ▁( this . job state . contains ( configuration key s . writer _ output _ dir )) ▁{ ▁log . warn ( string . format (\" property ▁% s ▁is ▁ deprecated . ▁x x ma j ▁no ▁need ▁to ▁use ▁it ▁if ▁% s ▁is ▁specified . \", ▁configuration key s . writer _ output _ dir , ▁configuration key s . task _ data _ root _ dir _ key )); ▁} ▁else ▁{ ▁x x ma j ▁string ▁working dir ▁= ▁this . job state . get prop ( configuration key s . task _ data _ root _ dir _ key ); ▁this . job state . set prop ( configuration key s . writer _ output _ dir , ▁new ▁path ( work ing dir , ▁task _ output _ dir _ name ) . to string ()); ▁log . info ( string ▁ . format (\" writer ▁x x ma j ▁output ▁x x ma j ▁directory ▁is ▁set ▁to ▁% s . \", ▁this . job state . get prop ( configuration key s . writer _ output _ dir ))); ▁} ▁}<$ comment $> if ▁{@ link ▁configuration key s ▁# ▁x x up ▁writer _ output _ dir } ▁( which ▁is ▁ deprecated ) ▁is ▁specified , ▁use ▁its ▁value . ▁x x ma j ▁otherwise , ▁if ▁{@ link ▁configuration key s ▁# ▁x x up ▁task _ data _ root _ dir _ key } ▁is ▁specified , ▁use ▁its ▁value ▁ plus ▁{@ link ▁# ▁x x up ▁task _ output _ dir _ name }.\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /tf/data/datasets;\n",
       "\n",
       "Valid: LabelList (1054 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁private ▁double ▁cal c total co st () ▁{ ▁double ▁cost ▁= ▁0; ▁for ▁( java . awt . component ▁com ▁: ▁j p store c art . get component s ()) ▁{ ▁if ▁( com ▁instanceof ▁i mat project . component s . sh op ping c art list entry ) ▁{ ▁i mat project . component s . sh op ping c art list entry ▁entry ▁= ▁( ( i mat project . component s . sh op ping c art list entry ) ▁( com )); ▁cost ▁= ▁cost ▁+ ▁( entry . get total ()); ▁} ▁} ▁return ▁cost ; ▁}<$ b ug $> no,▁x x bo s ▁float ▁get float ( int ▁b p ) ▁{ ▁data input stream ▁buf in ▁= ▁new ▁data input stream ( new ▁byte array input stream ( buf , ▁b p , ▁4 )); ▁try ▁{ ▁return ▁buf in . read float (); ▁} ▁catch ▁( io exception ▁e ) ▁{ ▁throw ▁new ▁assertion error ( e ); ▁} ▁}<$ comment $> extract ▁a ▁float ▁at ▁position ▁b p ▁from ▁buf .,▁x x bo s ▁@ java . lang . suppress warning s ( value ▁= ▁\" check style : illegal catch \") ▁public ▁void ▁update sub net route on tunnel up event ( org . open day light . y ang . gen . v 1. ur n . ie tf . param s . xml . ns . y ang . ie tf . y ang . types . rev 13 07 15 . uuid ▁sub net id , ▁java . math . big integer ▁ dp n id ) ▁{ ▁org . open day light . net v i rt . vpn manager . vpn sub net route handler . log . info (\" update sub net route on tunnel up event : ▁x x ma j ▁sub net ▁{} ▁x x ma j ▁ dp n ▁{}\", ▁sub net id . get value (), ▁ dp n id . to string ()); ▁try ▁{ ▁org . open day light . net v i rt . vpn manager . vpn util . lock sub net ( lock manager , ▁sub net id . get value ()); ▁try ▁{ ▁org . open day light . y ang tools . y ang . binding . instance identifier < org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry > ▁sub op identifier ▁= ▁org . open day light . y ang tools . y ang . binding . instance identifier . builder ( org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net op data . class ) . child ( org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry . class , ▁new ▁org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry key ( sub net id )) . build (); ▁com . google . common . base . optional < org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry > ▁optional sub s ▁= ▁org . open day light . net v i rt . vpn manager . vpn util . read ( data broker , ▁ logical data store type . operation al , ▁sub op identifier ); ▁if ▁(! ( optional sub s . is present ())) ▁{ ▁org . open day light . net v i rt . vpn manager . vpn sub net route handler . log . error (\" update sub net route on tunnel up event : ▁sub net op data entry ▁for ▁sub net ▁{} ▁is ▁not ▁available \", ▁sub net id . get value ()); ▁return ▁ ; ▁} ▁org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry ▁sub op entry ▁= ▁optional sub s . get (); ▁org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry builder ▁sub op builder ▁= ▁new ▁org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . sub net . op . data . sub net op data entry builder ( sub op entry ); ▁boolean ▁is external sub net vpn ▁= ▁org . open day light . net v i rt . vpn manager . vpn util . is external sub net vpn ( sub op entry . get vpn name (), ▁sub net id . get value ()); ▁if ▁( ( sub op builder . get route ad v state ()) ▁!= ▁( org . open day light . y ang . gen . v 1. ur n . open day light . net v i rt . l 3 vpn . rev 13 09 11 . task state . ad vert is ed )) ▁{ ▁if ▁( ( sub op builder . get n h dp n id ()) ▁== ▁null ) ▁{ ▁e lect new dp n for sub net route ( sub op builder , ▁null , ▁sub net id , ▁null , ▁(! is external sub net vpn )); ▁} else ▁if ▁(! is external sub net vpn ) ▁{ ▁get next h opt ep and publish route ( sub op builder , ▁sub net id ); ▁} ▁} ▁sub op entry ▁= ▁sub op builder . build (); ▁org . open day light . gen i us . md s al util . md s al util . sync write ( data broker , ▁ logical data store type . operation al , ▁sub op identifier , ▁sub op entry ); ▁org . open day light . net v i rt . vpn manager . vpn sub net route handler . log . info ( (\" update sub net route on tunnel up event : ▁x x ma j ▁updated ▁sub net op data entry ▁to ▁x x up ▁op ▁x x ma j ▁data store ▁ tunnel ▁up ▁on ▁ dp n \" ▁+ ▁\" ▁{} ▁for ▁sub net ▁{} \"), ▁ dp n id . to string (), ▁sub net id . get value ()); ▁} ▁catch ▁( java . lang . exception ▁ex ) ▁{ ▁org . open day light . net v i rt . vpn manager . vpn sub net route handler . log . error (\" c re ation ▁of ▁sub net op data entry ▁for ▁sub net ▁{} ▁failed \", ▁sub net id . get value (), ▁ex ); ▁} ▁finally ▁{ ▁org . open day light . net v i rt . vpn manager . vpn util . unlock sub net ( lock manager , ▁sub net id . get value ()); ▁} ▁} ▁catch ▁( java . lang . exception ▁e ) ▁{ ▁org . open day light . net v i rt . vpn manager . vpn sub net route handler . log . error (\" un able ▁to ▁handle ▁ tunnel ▁up ▁event ▁for ▁sub net id ▁{} ▁ dp n id ▁{}\", ▁sub net id . get value (), ▁ dp n id . to string (), ▁e ); ▁} ▁}<$ b ug $> yes,▁x x bo s ▁private ▁void ▁ s peak answer ( java . lang . string ▁msg ) ▁{ ▁title . set visibility ( view . g one ); ▁back . set visibility ( view . g one ); ▁next . set visibility ( view . g one ); ▁ s view . set visibility ( view . g one ); ▁t view . set visibility ( view . g one ); ▁ s view . set click able ( false ); ▁t view . set click able ( false ); ▁r layout . set visibility ( view . visible ); ▁safe p rm image view . set visibility ( view . visible ); ▁safe e y e contact image view . set visibility ( view . g one ); ▁safe bl ob . set visibility ( view . visible ); ▁safe bl ob . set background resource ( r . drawable . safe _ bl ob ); ▁safe record image button . set visibility ( view . visible ); ▁answer text view . set text ( msg ); ▁answer text view . set visibility ( view . g one ); ▁answer image view . set visibility ( view . g one ); ▁back . set background resource ( r . drawable . home _ selector ); ▁back . set visibility ( view . visible ); ▁on record ▁= ▁true ; ▁}<$ b ug $> yes,▁x x bo s ▁@ override ▁protected ▁void ▁on create ( bundle ▁saved instance state ) ▁{ ▁super . on create ( save d instance state ); ▁/ ▁/ ▁x x ma j ▁initialize ▁so cial ize ▁so cial ize . init a sync ( this , ▁new ▁so cial ize init listener () ▁{ ▁@ override ▁public ▁void ▁on error ( so cial ize exception ▁error ) ▁{ ▁/ ▁/ ▁x x ma j ▁handle ▁error ▁} ▁@ override ▁public ▁void ▁on init ( context ▁context , ▁i oc container ▁container ) ▁{ ▁/ ▁/ ▁x x ma j ▁if ▁you ▁want ▁to ▁access ▁x x ma j ▁so cial ize ▁directly , ▁do ▁it ▁here ▁} ▁} ); ▁}<$ comment $> begin - s n ip p et - 0\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /tf/data/datasets;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(8000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6a8a46b1e0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/tf/data/datasets/merged'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('transformer_save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file = model_path/'awd_lstm_do_30pc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_model(df_trn, file = model_path/'awd_lstm_do_30pc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# learn.recorder.plot_losses()\n",
    "figure_plot = learn.recorder.plot_losses(return_fig=True)\n",
    "figure_plot.savefig(fname=\"transformer_xl_plot_losses.png\", format='png')\n",
    "from PIL import Image\n",
    "Image.open('/tf/main/nbs/mdling/transformer_xl/transformer_xl_plot_losses.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_val[\"query\"][50000])\n",
    "print(\"\\n\\n\" + df_val[\"res\"][50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_val[\"query\"][75_000])\n",
    "print(\"\\n\\n\" + df_val[\"res\"][75_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(data_path/\"merged/model.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = df_val[\"query\"][500]\n",
    "N_WORDS = 200\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(TEXT)\n",
    "df_val[\"res\"][500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp.DecodePieces(learn.predict(TEXT, 100, temperature=0.75).split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs entire model's response up until special xxbos token,\n",
    "# i.e. once model begins a new sentence we consider the model finished with its answer.\n",
    "def get_res(mdl, inpt, n_toks = 1_000):\n",
    "    res = mdl.predict(inpt, n_toks, temperature=0.75).split(\" \")\n",
    "    res = sp.DecodePieces(res).split(\" \")\n",
    "    try:\n",
    "        end_res = res.index(\"xxbos\")\n",
    "    except:\n",
    "        end_res = len(res) - 1\n",
    "    \n",
    "    res = \" \".join(res[:end_res])[len(inpt.replace(\" \", '')):]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = get_res(learn, \"public static void main() {return;}<$bug$>\", n_toks = 10)\n",
    "res # [0:len(\"public static void main() {return;}<$bug$>\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def eval_txt(mdl, ds):\n",
    "    b1, b2, b3, b4 = [], [], [], []\n",
    "    meteor = []\n",
    "    rouge_l = []\n",
    "    preds = []\n",
    "    tokenizer = Tokenizer()\n",
    "    for inpt, lbl in zip(ds[\"query\"], ds[\"res\"]):\n",
    "        tok_len = len(sp.EncodeAsPieces(inpt))\n",
    "        if tok_len > 1024:\n",
    "            continue\n",
    "            \n",
    "        pred = get_res(mdl, inpt, n_toks = 600)\n",
    "        \n",
    "        tokens = tokenizer.process_all([lbl])\n",
    "        print(tokens)\n",
    "        lbl = ' '.join(tokens[0])\n",
    "        print(lbl)\n",
    "        preds.append(pred)\n",
    "        # bleu 1-4\n",
    "        b1.append(eval_bleu1([lbl], pred))\n",
    "        b2.append(eval_bleu2([lbl], pred))\n",
    "        b3.append(eval_bleu3([lbl], pred))\n",
    "        b4.append(eval_bleu4([lbl], pred))\n",
    "        \n",
    "        # meteor\n",
    "        meteor.append(eval_meteor([lbl], pred))\n",
    "        \n",
    "        # rouge\n",
    "        rouge_l.append(eval_rougeL_single_ref([lbl], pred))\n",
    "        \n",
    "    return b1, b2, b3, b4, meteor, rouge_l, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxmaj marshall the given parameter object .'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokens = tokenizer.process_all(df_val[-10:-9]['res'])\n",
    "# tokens\n",
    "' '.join(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_val.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean, median, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reads a file using a given resource map. @paramarn @return a map containing all the directorys that are notified'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'public synchronized Map<String, MLArray> read(InputStream stream) throws IOException\\n    {\\n        return read(stream, new MatFileFilter());\\n    }<$comment$>'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(df_val['query'][len(df_val) - 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['xxmaj', 'marshall', 'the', 'given', 'parameter', 'object', '.']]\n",
      "xxmaj marshall the given parameter object .\n",
      "[['xxmaj', 'gets', 'the', 'bridge', 'for', 'job', '.', '\\n \\n ', '@param', '_', 'jobname', 'the', '_', 'job', 'name', '\\n ', '@param', '_', 'prune', 'the', '_', 'prune', '\\n ', '@return', 'the', 'bridge4', 'job']]\n",
      "xxmaj gets the bridge for job . \n",
      " \n",
      "  @param _ jobname the _ job name \n",
      "  @param _ prune the _ prune \n",
      "  @return the bridge4 job\n",
      "[['xxmaj', 'reads', 'the', 'content', 'of', 'a', 'xxup', 'mat', '-', 'file', 'and', 'returns', 'the', 'mapped', 'content', '.', '\\n ', '<', 'p', '>', '\\n ', 'xxmaj', 'this', 'method', 'calls', '<', 'code', '>', 'read(stream', ',', 'new', 'matfilefilter', '(', ')', ')', '<', '/', 'code>.', '\\n \\n ', '@param', 'stream', '\\n ', 'a', 'valid', 'xxup', 'mat', '-', 'file', 'stream', 'to', 'be', 'read', '\\n ', '@return', 'the', 'same', 'as', '<', 'code>{@link', '#', 'getcontent', '(', ')', '}', '<', '/', 'code', '>', '\\n ', '@throws', 'ioexception', '\\n ', 'if', 'error', 'occurs', 'during', 'file', 'processing']]\n",
      "xxmaj reads the content of a xxup mat - file and returns the mapped content . \n",
      "  < p > \n",
      "  xxmaj this method calls < code > read(stream , new matfilefilter ( ) ) < / code>. \n",
      " \n",
      "  @param stream \n",
      "  a valid xxup mat - file stream to be read \n",
      "  @return the same as < code>{@link # getcontent ( ) } < / code > \n",
      "  @throws ioexception \n",
      "  if error occurs during file processing\n",
      "[['xxmaj', 'traverse', 'the', 'dag', 'to', 'determine', 'the', 'next', 'set', 'of', 'nodes', 'to', 'be', 'executed', '.', 'xxmaj', 'it', 'starts', 'with', 'the', 'startnodes', 'of', 'the', 'dag', 'and', '\\n ', 'identifies', 'each', 'node', 'yet', 'to', 'be', 'executed', 'and', 'for', 'which', 'each', 'of', 'its', 'parent', 'nodes', 'is', 'in', 'the', '{', '@link', 'executionstatus', '#', 'xxup', 'complete', '}', '\\n ', 'state', '.']]\n",
      "xxmaj traverse the dag to determine the next set of nodes to be executed . xxmaj it starts with the startnodes of the dag and \n",
      "  identifies each node yet to be executed and for which each of its parent nodes is in the { @link executionstatus # xxup complete } \n",
      "  state .\n",
      "[['stop', 'playback', 'of', 'a', 'mod', '\\n ', '@since', '01.07.2006']]\n",
      "stop playback of a mod \n",
      "  @since 01.07.2006\n",
      "[[' ', 'xxrep', '43', '=']]\n",
      "  xxrep 43 =\n",
      "[['xxmaj', 'sets', 'the', '(', 'selected', ')', 'context', 'of', 'a', '{', '@link', 'contextselectcombobox', '}', 'field', '.', '\\n ', '<', 'p', '>', '\\n ', 'xxmaj', 'the', 'call', 'to', 'this', 'method', 'has', 'no', 'effect', 'it', 'the', 'context', 'is', 'not', 'present', 'in', 'the', 'combo', 'box', '.', '\\n \\n ', '@param', 'fieldlabel', 'the', 'label', 'of', 'the', 'field', '\\n ', '@param', 'context', 'the', 'context', 'to', 'be', 'set', '/', 'selected', ',', '{', '@code', 'null', '}', 'to', 'clear', 'the', 'selection', '.', '\\n ', '@since', '2.6.0', '\\n ', '@see', '#', 'getcontextvalue(string', ')', '\\n ', '@see', '#', 'addcontextselectfield(string', ',', 'xxmaj', 'context', ')']]\n",
      "xxmaj sets the ( selected ) context of a { @link contextselectcombobox } field . \n",
      "  < p > \n",
      "  xxmaj the call to this method has no effect it the context is not present in the combo box . \n",
      " \n",
      "  @param fieldlabel the label of the field \n",
      "  @param context the context to be set / selected , { @code null } to clear the selection . \n",
      "  @since 2.6.0 \n",
      "  @see # getcontextvalue(string ) \n",
      "  @see # addcontextselectfield(string , xxmaj context )\n",
      "[['xxmaj', 'if', 'xxmaj', 'content', '-', 'xxmaj', 'type', 'header', 'is', 'not', 'set', ',', 'it', 'is', 'set', 'to', '\"', 'application', '/', 'octet', '-', 'stream', '\"', '.', '\\n \\n ', '@param', 'bytebuf', 'xxmaj', 'will', 'be', 'released']]\n",
      "xxmaj if xxmaj content - xxmaj type header is not set , it is set to \" application / octet - stream \" . \n",
      " \n",
      "  @param bytebuf xxmaj will be released\n",
      "[['xxmaj', 'construct', 'a', 'chaincode', 'endorsement', 'policy', 'from', 'a', 'stream', '.', '\\n \\n ', '@param', 'inputstream', '\\n ', '@throws', 'ioexception']]\n",
      "xxmaj construct a chaincode endorsement policy from a stream . \n",
      " \n",
      "  @param inputstream \n",
      "  @throws ioexception\n",
      "[['xxmaj', 'wraps', 'the', 'element', 'settings', 'with', 'access', 'wrappers.<p', '>', '\\n \\n ', '@param', 'cms', 'the', 'current', 'opencms', 'user', 'context', '\\n ', '@param', 'settings', 'the', 'settings', 'to', 'wrap', '\\n \\n ', '@return', 'the', 'element', 'settings', 'wrapped', 'in', 'access', 'wrappers']]\n",
      "xxmaj wraps the element settings with access wrappers.<p > \n",
      " \n",
      "  @param cms the current opencms user context \n",
      "  @param settings the settings to wrap \n",
      " \n",
      "  @return the element settings wrapped in access wrappers\n"
     ]
    }
   ],
   "source": [
    "b1, b2, b3, b4, meteor, rouge_l, preds  = eval_txt(learn, df_val[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marshall the given parameter object.',\n",
       " \"method to kill the current sale pwstcommands @param sp_property xxmaj the name of the s thiscommand to continue @return the job's defaults map\",\n",
       " 'reads all properties from a doc. xxmaj the inputstream is <code>null< / code>. @param  xxmaj the input stream @return xxmaj the stream of attachment',\n",
       " 'gets the given xxup eelement xxup cp nodeing structure. @param nodes the current treelist @return the first xxup nav node @throws kdfexception if not.',\n",
       " 'removes the context to the list of calls to the list.',\n",
       " '{@inheritdoc}',\n",
       " \"sets the field name for the field in the field. @param fieldname the name of the field when the field is set @param isdisplay true if the field can't be found, otherwise false\",\n",
       " 'transform a string to a string, call to xxup aws to read the content of the content, and returns it. xxmaj the {@link # ) method is called for {@code content} or {@link # format(int)}. @param id the common identifier of the content to be parsed. @param doc the document to deserialize the content to. @return the content of the document.',\n",
       " 'returns the inputstream stream @return',\n",
       " 'create an xxmaj map with the given xxmaj map unrecognized. @param cms the context @param cms the current context @param cms the current cms context @param cms the current context @param cms the current xxup cms context @param cmsproperty the cms cms context @return the cms properties from the given properties @throws cmsxmlexception @throws cmsxmlexception @throws cmsxmlexception @see # getxmltext() @see # getplaintext(cmsxmlcontentelement) @see # getxmltext(string)']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.179"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(rougue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>105263</td>\n",
       "      <td>private String getProjectIdForProjectName(Stri...</td>\n",
       "      <td>Return the project id for a given project name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105264</td>\n",
       "      <td>public File getFileFromDeletedFilesNotUpdated(...</td>\n",
       "      <td>Returns the name of the deleted file that is r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105265</td>\n",
       "      <td>public JobInformationRecorder withBatchInforma...</td>\n",
       "      <td>Indicates the JobInformationRecorder to persis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105266</td>\n",
       "      <td>public Object getAttribute(String name) {\\r\\n ...</td>\n",
       "      <td>返回这个窗口的私有属性或portal主控请求对象的共同属性\\n\\n@param name N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105267</td>\n",
       "      <td>public VolumeStatusItem withEvents(VolumeStatu...</td>\n",
       "      <td>&lt;p&gt;\\nA list of events associated with the volu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    query  \\\n",
       "105263  private String getProjectIdForProjectName(Stri...   \n",
       "105264  public File getFileFromDeletedFilesNotUpdated(...   \n",
       "105265  public JobInformationRecorder withBatchInforma...   \n",
       "105266  public Object getAttribute(String name) {\\r\\n ...   \n",
       "105267  public VolumeStatusItem withEvents(VolumeStatu...   \n",
       "\n",
       "                                                      res  \n",
       "105263  Return the project id for a given project name...  \n",
       "105264  Returns the name of the deleted file that is r...  \n",
       "105265  Indicates the JobInformationRecorder to persis...  \n",
       "105266  返回这个窗口的私有属性或portal主控请求对象的共同属性\\n\\n@param name N...  \n",
       "105267  <p>\\nA list of events associated with the volu...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val[-100:-95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iteratively after a {@link managementeventstreammanager}'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9277409729371751, 0.484819741733491, 0.2596623316452132)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(rouge_l[:][0]), mean(rouge_l[:][1]), mean(rouge_l[:][2])#, preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics for vulnerability detection - Accuracy, Precision, Recall\n",
    "def eval_vuln(mdl, tst):\n",
    "    tps, tns, fps, fns = 0, 0, 0, 0\n",
    "    tot = 0\n",
    "    for inpt, lbl in zip(tst[\"query\"], tst[\"res\"]):\n",
    "        tok_len = len(sp.EncodeAsPieces(inpt))\n",
    "        if tok_len > 1024:\n",
    "#             print(\"Skipping because size is too big\", tok_len)\n",
    "            continue\n",
    "        pred = get_res(mdl, inpt, n_toks = 10)\n",
    "        if lbl == \"yes\":\n",
    "            if pred == lbl:\n",
    "                tps += 1\n",
    "            else: fns += 1\n",
    "        else:\n",
    "            if pred == lbl:\n",
    "                tns += 1\n",
    "            else: fps += 1\n",
    "                \n",
    "        tot += 1\n",
    "        torch.cuda.empty_cache()\n",
    "            \n",
    "    acc   = (tps + tns) / tot\n",
    "    prec  = tps / (tps + fps) if (tps + fps) != 0 else 0.\n",
    "    recal = tps / (tps + fns) if (tps + fns) != 0 else 0.\n",
    "    \n",
    "    return acc, prec, recal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc, prec, recal = eval_vuln(learn, df_val[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, prec, recal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_val[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
